{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data and converting to panda dataframe (and changing/defining the names)\n",
    "\n",
    "\n",
    "\n",
    "data_file = '/Users/christianstenbro/Programming/ripley_project/Data_files/paper_data_streamlined.csv'\n",
    "\n",
    "data = pd.read_csv(data_file, sep=',', names=['ID', 'bib', 'abstract', 'rep_score'])\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing some rows from the dataframe (remember that python starts counting from 0 . . .):\n",
    "\n",
    "data.drop([0, 43, 92], axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 2586)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tfidf vectorizing the text and saving in a (sparse?) matrix\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "matrix = tfidf.fit_transform(data['abstract'].values.astype('U')) # the text needs to be converted to unicode strings (see https://stackoverflow.com/questions/39303912/tfidfvectorizer-in-scikit-learn-valueerror-np-nan-is-an-invalid-document)\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in': 1148,\n",
       " 'previous': 1781,\n",
       " 'studies': 2243,\n",
       " 'english': 793,\n",
       " 'examining': 835,\n",
       " 'the': 2334,\n",
       " 'influence': 1184,\n",
       " 'of': 1580,\n",
       " 'phonological': 1699,\n",
       " 'neighbourhood': 1522,\n",
       " 'density': 642,\n",
       " 'spoken': 2187,\n",
       " 'word': 2557,\n",
       " 'production': 1812,\n",
       " 'words': 2558,\n",
       " 'with': 2553,\n",
       " 'many': 1393,\n",
       " 'similar': 2126,\n",
       " 'sounding': 2167,\n",
       " 'or': 1609,\n",
       " 'dense': 641,\n",
       " 'were': 2531,\n",
       " 'produced': 1810,\n",
       " 'more': 1474,\n",
       " 'quickly': 1859,\n",
       " 'and': 185,\n",
       " 'accurately': 97,\n",
       " 'than': 2332,\n",
       " 'few': 928,\n",
       " 'sparse': 2172,\n",
       " 'on': 1589,\n",
       " 'process': 1804,\n",
       " 'spanish': 2171,\n",
       " 'was': 2519,\n",
       " 'examined': 833,\n",
       " 'picture': 1710,\n",
       " 'naming': 1502,\n",
       " 'task': 2312,\n",
       " 'results': 1999,\n",
       " 'showed': 2112,\n",
       " 'that': 2333,\n",
       " 'pictures': 1711,\n",
       " 'names': 1501,\n",
       " 'from': 987,\n",
       " 'neighbourhoods': 1523,\n",
       " 'named': 1499,\n",
       " 'present': 1771,\n",
       " 'pattern': 1663,\n",
       " 'is': 1254,\n",
       " 'opposite': 1606,\n",
       " 'what': 2533,\n",
       " 'has': 1048,\n",
       " 'been': 309,\n",
       " 'previously': 1782,\n",
       " 'found': 972,\n",
       " 'speech': 2180,\n",
       " 'we': 2523,\n",
       " 'hypothesise': 1102,\n",
       " 'differences': 677,\n",
       " 'morphology': 1482,\n",
       " 'location': 1362,\n",
       " 'where': 2536,\n",
       " 'neighbours': 1524,\n",
       " 'tend': 2321,\n",
       " 'to': 2366,\n",
       " 'occur': 1576,\n",
       " 'may': 1408,\n",
       " 'contribute': 555,\n",
       " 'processing': 1807,\n",
       " 'observed': 1571,\n",
       " 'two': 2410,\n",
       " 'languages': 1289,\n",
       " 'psycinfo': 1845,\n",
       " 'database': 607,\n",
       " 'record': 1906,\n",
       " '2016': 33,\n",
       " 'apa': 197,\n",
       " 'all': 150,\n",
       " 'rights': 2023,\n",
       " 'reserved': 1983,\n",
       " 'infants': 1177,\n",
       " 'acquire': 101,\n",
       " 'whatever': 2534,\n",
       " 'language': 1288,\n",
       " 'environment': 803,\n",
       " 'into': 1233,\n",
       " 'which': 2542,\n",
       " 'they': 2349,\n",
       " 'are': 216,\n",
       " 'born': 348,\n",
       " 'mental': 1432,\n",
       " 'capability': 369,\n",
       " 'newborn': 1530,\n",
       " 'child': 403,\n",
       " 'not': 1552,\n",
       " 'biased': 329,\n",
       " 'any': 196,\n",
       " 'way': 2521,\n",
       " 'towards': 2377,\n",
       " 'acquisition': 103,\n",
       " 'one': 1590,\n",
       " 'human': 1092,\n",
       " 'rather': 1874,\n",
       " 'another': 190,\n",
       " 'because': 307,\n",
       " 'psychologists': 1843,\n",
       " 'who': 2545,\n",
       " 'attempt': 266,\n",
       " 'model': 1452,\n",
       " 'comprehension': 473,\n",
       " 'interested': 1214,\n",
       " 'structure': 2235,\n",
       " 'mind': 1444,\n",
       " 'properties': 1824,\n",
       " 'individual': 1171,\n",
       " 'strategies': 2222,\n",
       " 'incorporate': 1155,\n",
       " 'their': 2336,\n",
       " 'models': 1454,\n",
       " 'presumed': 1777,\n",
       " 'be': 304,\n",
       " 'universal': 2441,\n",
       " 'specific': 2176,\n",
       " 'other': 1621,\n",
       " 'characteristic': 395,\n",
       " 'system': 2299,\n",
       " 'say': 2046,\n",
       " 'french': 983,\n",
       " 'igbo': 1119,\n",
       " 'systems': 2302,\n",
       " 'report': 1966,\n",
       " 'here': 1065,\n",
       " 'however': 1089,\n",
       " 'strategy': 2223,\n",
       " 'appears': 204,\n",
       " 'used': 2458,\n",
       " 'by': 362,\n",
       " 'native': 1505,\n",
       " 'speakers': 2175,\n",
       " 'but': 361,\n",
       " 'segmentation': 2064,\n",
       " 'procedures': 1803,\n",
       " 'differ': 674,\n",
       " 'different': 678,\n",
       " 'earlier': 750,\n",
       " 'work': 2560,\n",
       " 'based': 298,\n",
       " 'listening': 1351,\n",
       " 'suggested': 2265,\n",
       " 'syllable': 2290,\n",
       " 'functions': 996,\n",
       " 'as': 234,\n",
       " 'unit': 2439,\n",
       " 'while': 2543,\n",
       " 'relatively': 1943,\n",
       " 'regular': 1931,\n",
       " 'clearly': 425,\n",
       " 'bounded': 354,\n",
       " 'syllables': 2291,\n",
       " 'such': 2260,\n",
       " 'do': 723,\n",
       " 'no': 1536,\n",
       " 'trace': 2379,\n",
       " 'syllabifying': 2289,\n",
       " 'listeners': 1350,\n",
       " 'nonsense': 1545,\n",
       " 'evidence': 825,\n",
       " 'syllabification': 2287,\n",
       " 'even': 821,\n",
       " 'when': 2535,\n",
       " 'conclude': 485,\n",
       " 'alternative': 162,\n",
       " 'routines': 2034,\n",
       " 'available': 284,\n",
       " 'processor': 1808,\n",
       " 'some': 2160,\n",
       " 'cases': 379,\n",
       " 'involve': 1249,\n",
       " 'operation': 1601,\n",
       " 'procedure': 1802,\n",
       " 'sentences': 2080,\n",
       " 'contrastive': 553,\n",
       " 'intonation': 1234,\n",
       " 'contour': 548,\n",
       " 'usually': 2464,\n",
       " 'speaker': 2174,\n",
       " 'entertains': 800,\n",
       " 'alternatives': 163,\n",
       " 'accented': 82,\n",
       " 'frequently': 986,\n",
       " 'without': 2555,\n",
       " 'making': 1385,\n",
       " 'explicit': 866,\n",
       " 'for': 960,\n",
       " 'listener': 1349,\n",
       " 'cross': 592,\n",
       " 'modal': 1451,\n",
       " 'associative': 256,\n",
       " 'priming': 1789,\n",
       " 'experiments': 863,\n",
       " 'tested': 2328,\n",
       " 'dutch': 744,\n",
       " 'whether': 2539,\n",
       " 'contextual': 544,\n",
       " 'become': 308,\n",
       " 'upon': 2455,\n",
       " 'hearing': 1056,\n",
       " 'sentence': 2079,\n",
       " 'compared': 451,\n",
       " 'non': 1539,\n",
       " 'first': 941,\n",
       " 'experiment': 860,\n",
       " 'recognition': 1901,\n",
       " 'associates': 253,\n",
       " 'final': 935,\n",
       " 'primes': 1788,\n",
       " 'second': 2057,\n",
       " 'generic': 1015,\n",
       " 'facilitated': 892,\n",
       " 'occurred': 1577,\n",
       " 'weakly': 2525,\n",
       " 'independent': 1164,\n",
       " 'possibly': 1739,\n",
       " 'contours': 549,\n",
       " 'trigger': 2401,\n",
       " 'an': 175,\n",
       " 'accommodation': 87,\n",
       " 'mechanism': 1422,\n",
       " 'retrieve': 2004,\n",
       " 'contrast': 551,\n",
       " 'recent': 1895,\n",
       " 'theories': 2342,\n",
       " 'morphological': 1480,\n",
       " 'have': 1049,\n",
       " 'dominated': 728,\n",
       " 'notion': 1556,\n",
       " 'morphologically': 1481,\n",
       " 'complex': 462,\n",
       " 'decomposed': 616,\n",
       " 'constituents': 524,\n",
       " 'basis': 302,\n",
       " 'semantic': 2071,\n",
       " 'this': 2351,\n",
       " 'article': 229,\n",
       " 'argue': 217,\n",
       " 'weight': 2527,\n",
       " 'now': 1560,\n",
       " 'suggests': 2267,\n",
       " 'begins': 313,\n",
       " 'rapid': 1869,\n",
       " 'morphemic': 1478,\n",
       " 'solely': 2157,\n",
       " 'analysis': 179,\n",
       " 'orthography': 1619,\n",
       " 'following': 958,\n",
       " 'review': 2015,\n",
       " 'discuss': 696,\n",
       " 'characteristics': 396,\n",
       " 'form': 964,\n",
       " 'decomposition': 617,\n",
       " 'speculate': 2179,\n",
       " 'its': 1259,\n",
       " 'purpose': 1850,\n",
       " 'might': 1442,\n",
       " 'consider': 510,\n",
       " 'how': 1088,\n",
       " 'it': 1256,\n",
       " 'learned': 1309,\n",
       " 'developing': 670,\n",
       " 'reader': 1880,\n",
       " 'describe': 651,\n",
       " 'known': 1278,\n",
       " 'neural': 1525,\n",
       " 'bases': 299,\n",
       " 'our': 1623,\n",
       " 'discussion': 699,\n",
       " 'ends': 792,\n",
       " 'reflecting': 1921,\n",
       " 'semantically': 2072,\n",
       " 're': 1876,\n",
       " 'interpreted': 1228,\n",
       " 'context': 542,\n",
       " 'orthographically': 1618,\n",
       " 'described': 652,\n",
       " 'gating': 1005,\n",
       " 'paradigm': 1642,\n",
       " 'grosjean': 1034,\n",
       " '1980': 14,\n",
       " 'determine': 665,\n",
       " 'whethersubjects': 2540,\n",
       " 'potentially': 1745,\n",
       " 'last': 1294,\n",
       " 'thiscase': 2352,\n",
       " 'noun': 1557,\n",
       " 'before': 310,\n",
       " 'optional': 1607,\n",
       " 'prepositional': 1768,\n",
       " 'phrase': 1705,\n",
       " 'can': 365,\n",
       " 'indicate': 1168,\n",
       " 'whetherthe': 2541,\n",
       " 'over': 1628,\n",
       " 'if': 1118,\n",
       " 'much': 1492,\n",
       " 'longer': 1368,\n",
       " 'will': 2550,\n",
       " 'contained': 537,\n",
       " 'endings': 791,\n",
       " 'ranging': 1868,\n",
       " 'length': 1318,\n",
       " 'zero': 2583,\n",
       " 'nine': 1533,\n",
       " 'wordswere': 2559,\n",
       " 'gated': 1004,\n",
       " 'object': 1566,\n",
       " 'presented': 1773,\n",
       " 'subjects': 2249,\n",
       " 'had': 1042,\n",
       " 'choosewhich': 411,\n",
       " 'four': 973,\n",
       " 'being': 315,\n",
       " 'press': 1776,\n",
       " 'key': 1270,\n",
       " 'at': 262,\n",
       " 'point': 1725,\n",
       " 'timewhen': 2364,\n",
       " 'felt': 923,\n",
       " 'would': 2566,\n",
       " 'ended': 789,\n",
       " 'full': 991,\n",
       " 'basing': 301,\n",
       " 'themselves': 2339,\n",
       " 'prosodic': 1831,\n",
       " 'cues': 595,\n",
       " 'subjectswere': 2250,\n",
       " 'surprisingly': 2283,\n",
       " 'accurate': 96,\n",
       " 'predicting': 1754,\n",
       " 'upcoming': 2454,\n",
       " 'acoustic': 100,\n",
       " 'test': 2327,\n",
       " 'strong': 2229,\n",
       " 'relationshipbetween': 1940,\n",
       " 'measures': 1420,\n",
       " 'fundamental': 997,\n",
       " 'frequency': 984,\n",
       " 'amplitude': 174,\n",
       " 'duration': 742,\n",
       " 'andthe': 186,\n",
       " 'experimental': 861,\n",
       " 'data': 606,\n",
       " 'these': 2348,\n",
       " 'findings': 939,\n",
       " 'discussed': 697,\n",
       " 'terms': 2326,\n",
       " 'predictiveand': 1757,\n",
       " 'interpretative': 1227,\n",
       " 'roles': 2031,\n",
       " 'prosody': 1833,\n",
       " 'during': 743,\n",
       " 'line': 1342,\n",
       " 'lan': 1287,\n",
       " 'guage': 1039,\n",
       " 'concepts': 480,\n",
       " 'stereotypes': 2210,\n",
       " 'leaves': 1313,\n",
       " 'open': 1599,\n",
       " 'question': 1857,\n",
       " 'argued': 218,\n",
       " 'elsewhere': 771,\n",
       " 'identify': 1113,\n",
       " 'stereotypical': 2211,\n",
       " 'instances': 1198,\n",
       " 'rosch': 2032,\n",
       " '1978': 13,\n",
       " 'principles': 1791,\n",
       " 'categorization': 383,\n",
       " 'lloyd': 1357,\n",
       " 'ed': 757,\n",
       " 'cognition': 432,\n",
       " 'hillsdale': 1076,\n",
       " 'nj': 1535,\n",
       " 'lawrence': 1301,\n",
       " 'erlbaum': 810,\n",
       " 'smith': 2154,\n",
       " 'medin': 1425,\n",
       " '1981': 15,\n",
       " 'categories': 382,\n",
       " 'cambridge': 363,\n",
       " 'ma': 1377,\n",
       " 'harvard': 1047,\n",
       " 'university': 2442,\n",
       " 'fail': 902,\n",
       " 'provide': 1836,\n",
       " 'adequate': 121,\n",
       " 'account': 91,\n",
       " 'compositionality': 468,\n",
       " 'fodor': 954,\n",
       " 'lepore': 1320,\n",
       " '1996': 20,\n",
       " 'red': 1909,\n",
       " 'herring': 1066,\n",
       " 'pet': 1685,\n",
       " 'fish': 942,\n",
       " 'why': 2548,\n",
       " 'still': 2214,\n",
       " 'cannot': 366,\n",
       " 'prototypes': 1834,\n",
       " '58': 59,\n",
       " '253': 37,\n",
       " '270': 40,\n",
       " '1998': 22,\n",
       " 'cognitive': 433,\n",
       " 'science': 2051,\n",
       " 'went': 2530,\n",
       " 'wrong': 2568,\n",
       " 'new': 1529,\n",
       " 'york': 2578,\n",
       " 'ny': 1565,\n",
       " 'oxford': 1633,\n",
       " 'paper': 1641,\n",
       " 'extends': 881,\n",
       " 'argument': 220,\n",
       " 'reports': 1968,\n",
       " 'suggesting': 2266,\n",
       " 'participants': 1653,\n",
       " 'assume': 258,\n",
       " 'default': 622,\n",
       " 'inherit': 1188,\n",
       " 'thus': 2361,\n",
       " 'propositions': 1830,\n",
       " 'baby': 289,\n",
       " 'ducks': 740,\n",
       " 'webbed': 2526,\n",
       " 'feet': 922,\n",
       " 'judged': 1264,\n",
       " 'less': 1321,\n",
       " 'likely': 1339,\n",
       " 'true': 2405,\n",
       " 'like': 1336,\n",
       " 'moreover': 1475,\n",
       " 'manipulation': 1391,\n",
       " 'type': 2411,\n",
       " 'number': 1561,\n",
       " 'modifiers': 1457,\n",
       " 'revealed': 2008,\n",
       " 'systematic': 2300,\n",
       " 'departure': 643,\n",
       " 'unmodified': 2447,\n",
       " 'stereotype': 2209,\n",
       " 'both': 351,\n",
       " 'addition': 113,\n",
       " 'quacking': 1852,\n",
       " 'versus': 2494,\n",
       " 'modifier': 1456,\n",
       " 'peruvian': 1684,\n",
       " 'general': 1008,\n",
       " 'case': 378,\n",
       " 'head': 1051,\n",
       " 'systematically': 2301,\n",
       " 'discounted': 690,\n",
       " 'combines': 444,\n",
       " 'effect': 759,\n",
       " 'represents': 1974,\n",
       " 'principle': 1790,\n",
       " 'conceptual': 481,\n",
       " 'combination': 440,\n",
       " 'argues': 219,\n",
       " 'against': 142,\n",
       " 'inheritance': 1189,\n",
       " 'features': 918,\n",
       " 'instead': 1199,\n",
       " 'advocate': 134,\n",
       " 'remain': 1950,\n",
       " 'inert': 1176,\n",
       " 'under': 2426,\n",
       " 'supported': 2276,\n",
       " 'separate': 2081,\n",
       " 'machinery': 1378,\n",
       " 'introduces': 1236,\n",
       " 'pragmatic': 1749,\n",
       " 'knowledge': 1277,\n",
       " 'dependent': 647,\n",
       " 'inferences': 1179,\n",
       " 'investigated': 1243,\n",
       " 'ambiguous': 169,\n",
       " 'containing': 539,\n",
       " 'complement': 458,\n",
       " 'verbs': 2491,\n",
       " 'believe': 316,\n",
       " 'followed': 957,\n",
       " 'direct': 686,\n",
       " 'clause': 422,\n",
       " 'types': 2412,\n",
       " 'unambiguous': 2420,\n",
       " 'clauses': 423,\n",
       " 'introduced': 1235,\n",
       " '33': 50,\n",
       " 'undergraduates': 2429,\n",
       " 'processed': 1805,\n",
       " 'numerous': 1563,\n",
       " 'reading': 1883,\n",
       " 'disambiguation': 689,\n",
       " 'after': 140,\n",
       " 'times': 2363,\n",
       " 'obtained': 1573,\n",
       " 'reduced': 1911,\n",
       " 'constructions': 533,\n",
       " 'complements': 460,\n",
       " 'concluded': 486,\n",
       " 'complexity': 463,\n",
       " 'difference': 676,\n",
       " 'does': 725,\n",
       " 'represent': 1970,\n",
       " 'garden': 1003,\n",
       " 'pathing': 1661,\n",
       " 'reanalysis': 1887,\n",
       " 'result': 1997,\n",
       " 'minimal': 1445,\n",
       " 'attachment': 264,\n",
       " 'proposed': 1829,\n",
       " 'frazier': 981,\n",
       " 'rayner': 1875,\n",
       " 'see': 2060,\n",
       " '1982': 16,\n",
       " '20309': 34,\n",
       " '001': 0,\n",
       " 'reflect': 1919,\n",
       " 'extra': 883,\n",
       " 'caused': 386,\n",
       " 'having': 1050,\n",
       " 'handle': 1045,\n",
       " 'sets': 2089,\n",
       " 'clausal': 421,\n",
       " 'relations': 1938,\n",
       " 'just': 1267,\n",
       " 'interference': 1218,\n",
       " 'reported': 1967,\n",
       " 'boundaries': 352,\n",
       " 'explored': 871,\n",
       " 'car': 373,\n",
       " 'appeared': 203,\n",
       " 'superimposed': 2273,\n",
       " 'distractors': 719,\n",
       " 'distractor': 718,\n",
       " 'same': 2044,\n",
       " 'category': 384,\n",
       " 'whereas': 2537,\n",
       " 'related': 1934,\n",
       " 'bumper': 360,\n",
       " 'led': 1315,\n",
       " 'facilitation': 893,\n",
       " 'replicated': 1964,\n",
       " 'relationship': 1939,\n",
       " 'between': 325,\n",
       " 'necessarily': 1512,\n",
       " 'lead': 1304,\n",
       " 'fact': 895,\n",
       " 'until': 2452,\n",
       " 'implications': 1139,\n",
       " 'assumption': 260,\n",
       " 'arises': 222,\n",
       " 'consequence': 508,\n",
       " 'lexical': 1327,\n",
       " 'competition': 456,\n",
       " 'stroop': 2232,\n",
       " 'color': 438,\n",
       " 'administered': 125,\n",
       " 'children': 405,\n",
       " 'unable': 2418,\n",
       " 'read': 1879,\n",
       " 'hundred': 1093,\n",
       " 'sixty': 2140,\n",
       " 'eight': 763,\n",
       " '3½': 53,\n",
       " '6½': 62,\n",
       " 'years': 2574,\n",
       " '50': 58,\n",
       " 'female': 924,\n",
       " '24': 36,\n",
       " 'each': 749,\n",
       " 'month': 1473,\n",
       " 'interval': 1231,\n",
       " 'shown': 2114,\n",
       " 'drawings': 736,\n",
       " 'familiar': 906,\n",
       " 'objects': 1567,\n",
       " 'congruent': 503,\n",
       " 'orange': 1610,\n",
       " 'carrot': 376,\n",
       " 'incongruent': 1153,\n",
       " 'green': 1032,\n",
       " 'neutral': 1528,\n",
       " 'canonical': 367,\n",
       " 'book': 345,\n",
       " 'abstract': 79,\n",
       " 'shapes': 2100,\n",
       " 'drawn': 737,\n",
       " 'six': 2139,\n",
       " 'colors': 439,\n",
       " 'half': 1043,\n",
       " 'asked': 238,\n",
       " 'name': 1498,\n",
       " 'predominant': 1760,\n",
       " 'tendency': 2322,\n",
       " 'instructed': 1200,\n",
       " 'otherwise': 1622,\n",
       " 'slower': 2151,\n",
       " 'faster': 912,\n",
       " 'stimulus': 2216,\n",
       " 'could': 583,\n",
       " 'shape': 2099,\n",
       " 'heightened': 1062,\n",
       " 'due': 741,\n",
       " 'lack': 1283,\n",
       " 'familiarity': 907,\n",
       " 'group': 1036,\n",
       " 'condition': 491,\n",
       " 'fast': 911,\n",
       " 'most': 1483,\n",
       " 'productive': 1814,\n",
       " 'class': 416,\n",
       " 'exemplified': 843,\n",
       " 'verb': 2487,\n",
       " 'string': 2226,\n",
       " 'strung': 2239,\n",
       " 'historical': 1078,\n",
       " 'show': 2111,\n",
       " 'phono': 1697,\n",
       " 'logically': 1366,\n",
       " 'defined': 625,\n",
       " 'members': 1428,\n",
       " 'share': 2101,\n",
       " 'single': 2137,\n",
       " 'set': 2088,\n",
       " 'fea': 914,\n",
       " 'tures': 2407,\n",
       " 'organized': 1613,\n",
       " 'around': 224,\n",
       " 'prototypical': 1835,\n",
       " 'member': 1427,\n",
       " 'sense': 2074,\n",
       " 'stand': 2197,\n",
       " 'family': 908,\n",
       " 'resemblance': 1982,\n",
       " 'relation': 1937,\n",
       " 'wittgenstein': 2556,\n",
       " '1953': 10,\n",
       " 'defining': 626,\n",
       " 'attributes': 275,\n",
       " 'include': 1149,\n",
       " 'consonants': 521,\n",
       " 'well': 2529,\n",
       " 'initial': 1193,\n",
       " 'consonant': 519,\n",
       " 'clusters': 429,\n",
       " 'lesser': 1322,\n",
       " 'extent': 882,\n",
       " 'vowel': 2511,\n",
       " 'base': 297,\n",
       " 'organization': 1612,\n",
       " 'formal': 965,\n",
       " 'aspects': 239,\n",
       " 'linguistic': 1344,\n",
       " 'units': 2440,\n",
       " 'follow': 956,\n",
       " 'content': 541,\n",
       " 'classes': 417,\n",
       " 'natural': 1506,\n",
       " 'cultural': 596,\n",
       " 'examines': 834,\n",
       " 'talkers': 2309,\n",
       " 'utterances': 2468,\n",
       " 'time': 2362,\n",
       " 'monolog': 1470,\n",
       " 'old': 1586,\n",
       " 'finding': 938,\n",
       " 'distinguish': 715,\n",
       " 'shortening': 2108,\n",
       " 'them': 2337,\n",
       " 'intelligible': 1208,\n",
       " 'isolation': 1255,\n",
       " 'probably': 1797,\n",
       " 'identifiable': 1109,\n",
       " 'infer': 1178,\n",
       " 'attenuate': 271,\n",
       " 'productions': 1813,\n",
       " 'so': 2155,\n",
       " 'sacrificing': 2039,\n",
       " 'communicative': 449,\n",
       " 'efficacy': 761,\n",
       " 'repetitions': 1962,\n",
       " 'items': 1258,\n",
       " 'support': 2275,\n",
       " 'receive': 1891,\n",
       " 'use': 2457,\n",
       " 'information': 1187,\n",
       " 'anaphor': 182,\n",
       " 'promote': 1818,\n",
       " 'retrieval': 2002,\n",
       " 'series': 2085,\n",
       " 'three': 2356,\n",
       " 'exploring': 872,\n",
       " 'effects': 760,\n",
       " 'repeated': 1959,\n",
       " 'aloud': 158,\n",
       " 'auditorily': 278,\n",
       " 'then': 2340,\n",
       " 'targets': 2311,\n",
       " 'prime': 1786,\n",
       " 'target': 2310,\n",
       " 'shared': 2102,\n",
       " 'phonemes': 1693,\n",
       " 'only': 1594,\n",
       " 'occupied': 1575,\n",
       " 'syllabic': 2286,\n",
       " 'positions': 1735,\n",
       " 'degree': 629,\n",
       " 'unaffected': 2419,\n",
       " 'lexicality': 1328,\n",
       " 'early': 751,\n",
       " 'late': 1295,\n",
       " 'intervals': 1232,\n",
       " 'response': 1994,\n",
       " 'tease': 2317,\n",
       " 'apart': 198,\n",
       " 'contributions': 558,\n",
       " 'automatic': 281,\n",
       " 'strategic': 2221,\n",
       " 'processes': 1806,\n",
       " 'considered': 513,\n",
       " 'current': 599,\n",
       " 'accounts': 93,\n",
       " 'portuguese': 1732,\n",
       " 'materials': 1405,\n",
       " 'consistency': 516,\n",
       " 'ziegler': 2585,\n",
       " 'ferrand': 926,\n",
       " 'rimes': 2025,\n",
       " 'spelled': 2184,\n",
       " 'ways': 2522,\n",
       " 'inconsistent': 1154,\n",
       " 'auditory': 279,\n",
       " 'decision': 611,\n",
       " 'latencies': 1296,\n",
       " 'errors': 812,\n",
       " 'did': 673,\n",
       " 'consistent': 517,\n",
       " 'shadowing': 2097,\n",
       " 'orthographic': 1617,\n",
       " 'confinement': 495,\n",
       " 'influences': 1185,\n",
       " 'either': 764,\n",
       " 'decisional': 612,\n",
       " 'tried': 2400,\n",
       " 'untangle': 2451,\n",
       " 'interpretations': 1226,\n",
       " 'comparing': 452,\n",
       " 'situations': 2138,\n",
       " 'made': 1379,\n",
       " 'contingent': 545,\n",
       " 'phonemic': 1694,\n",
       " 'criterion': 590,\n",
       " 'significant': 2124,\n",
       " 'lexically': 1329,\n",
       " 'sublexical': 2252,\n",
       " 'affected': 136,\n",
       " 'course': 587,\n",
       " 'encoding': 785,\n",
       " 'methodology': 1440,\n",
       " 'required': 1977,\n",
       " 'monitor': 1465,\n",
       " 'internal': 1220,\n",
       " 'prespecified': 1775,\n",
       " 'segments': 2065,\n",
       " 'demonstrated': 639,\n",
       " 'monitored': 1466,\n",
       " 'significantly': 2125,\n",
       " 'concurrent': 490,\n",
       " 'articulation': 231,\n",
       " '1b': 24,\n",
       " 'limited': 1341,\n",
       " 'performance': 1676,\n",
       " 'excluding': 839,\n",
       " 'possibility': 1737,\n",
       " 'monitoring': 1467,\n",
       " 'subvocal': 2258,\n",
       " 'carrier': 374,\n",
       " 'timing': 2365,\n",
       " 'overt': 1631,\n",
       " 'therefore': 2347,\n",
       " 'phonetic': 1695,\n",
       " 'representation': 1971,\n",
       " 'replicate': 1963,\n",
       " 'perception': 1672,\n",
       " 'responses': 1995,\n",
       " 'corresponded': 574,\n",
       " 'generation': 1014,\n",
       " 'syllabified': 2288,\n",
       " 'provides': 1838,\n",
       " 'detailed': 661,\n",
       " 'concerning': 483,\n",
       " 'within': 2554,\n",
       " 'amendments': 170,\n",
       " 'light': 1334,\n",
       " 'observation': 1569,\n",
       " 'favor': 913,\n",
       " 'functional': 994,\n",
       " 'role': 2030,\n",
       " 'stored': 2218,\n",
       " 'accordingly': 90,\n",
       " 'various': 2479,\n",
       " 'theoretical': 2341,\n",
       " 'postulate': 1741,\n",
       " 'repository': 1969,\n",
       " 'representations': 1972,\n",
       " 'accessed': 84,\n",
       " 'empirical': 780,\n",
       " 'locating': 1361,\n",
       " 'level': 1325,\n",
       " 'motor': 1486,\n",
       " 'programming': 1817,\n",
       " 'levels': 1326,\n",
       " 'scarce': 2048,\n",
       " 'investigate': 1242,\n",
       " 'origin': 1614,\n",
       " 'conducted': 494,\n",
       " 'involving': 1251,\n",
       " 'immediate': 1128,\n",
       " 'delayed': 633,\n",
       " 'interfering': 1219,\n",
       " 'articulatory': 232,\n",
       " 'suppression': 2280,\n",
       " 'psycholinguistic': 1841,\n",
       " 'short': 2107,\n",
       " 'term': 2325,\n",
       " 'memory': 1431,\n",
       " 'allows': 156,\n",
       " 'working': 2562,\n",
       " 'hypothesis': 1101,\n",
       " 'disrupts': 706,\n",
       " 'leaving': 1314,\n",
       " 'intact': 1204,\n",
       " 'pseudo': 1839,\n",
       " 'respectively': 1989,\n",
       " 'delay': 632,\n",
       " 'presentation': 1772,\n",
       " 'cue': 593,\n",
       " 'filled': 932,\n",
       " 'standard': 2198,\n",
       " 'highly': 1074,\n",
       " 'affects': 137,\n",
       " 'stage': 2195,\n",
       " 'interpretation': 1225,\n",
       " 'postulated': 1742,\n",
       " 'involves': 1250,\n",
       " 'sized': 2141,\n",
       " 'visual': 2504,\n",
       " 'world': 2563,\n",
       " 'eye': 886,\n",
       " 'tracking': 2381,\n",
       " 'prediction': 1755,\n",
       " 'repair': 1956,\n",
       " 'disfluencies': 700,\n",
       " 'chef': 401,\n",
       " 'reached': 1877,\n",
       " 'salt': 2043,\n",
       " 'uh': 2416,\n",
       " 'mean': 1411,\n",
       " 'ketchup': 1269,\n",
       " 'fixate': 944,\n",
       " 'critical': 591,\n",
       " 'item': 1257,\n",
       " 'pepper': 1669,\n",
       " 'coordination': 568,\n",
       " 'structures': 2237,\n",
       " 'also': 160,\n",
       " 'disfluency': 701,\n",
       " 'fixations': 946,\n",
       " 'fixation': 945,\n",
       " 'patterns': 1664,\n",
       " 'employing': 782,\n",
       " 'focus': 953,\n",
       " 'suggest': 2264,\n",
       " 'mechanisms': 1423,\n",
       " 'underlie': 2430,\n",
       " 'generating': 1013,\n",
       " 'entities': 801,\n",
       " 'reparandum': 1957,\n",
       " 'negated': 1515,\n",
       " 'entity': 802,\n",
       " 'vowels': 2512,\n",
       " 'importance': 1144,\n",
       " 'recently': 1896,\n",
       " 'play': 1718,\n",
       " 'important': 1145,\n",
       " 'adult': 127,\n",
       " 'proposal': 1827,\n",
       " 'started': 2200,\n",
       " 'receiving': 1894,\n",
       " 'developmental': 672,\n",
       " 'showing': 2113,\n",
       " 'better': 324,\n",
       " 'consonantal': 520,\n",
       " 'vocalic': 2509,\n",
       " 'learning': 1311,\n",
       " 'received': 1892,\n",
       " 'study': 2244,\n",
       " 'directly': 688,\n",
       " 'relative': 1942,\n",
       " 'access': 83,\n",
       " 'using': 2462,\n",
       " 'masked': 1399,\n",
       " 'identity': 1114,\n",
       " 'joli': 1263,\n",
       " 'unrelated': 2450,\n",
       " 'vabu': 2469,\n",
       " 'jalu': 1261,\n",
       " 'vobi': 2506,\n",
       " 'conditions': 493,\n",
       " 'establish': 816,\n",
       " 'privileged': 1794,\n",
       " 'eyetracking': 887,\n",
       " 'plurality': 1722,\n",
       " 'parsing': 1651,\n",
       " 'decisions': 613,\n",
       " 'temporarily': 2320,\n",
       " 'reciprocal': 1898,\n",
       " 'lovers': 1372,\n",
       " 'kissed': 1273,\n",
       " 'played': 1719,\n",
       " 'alone': 157,\n",
       " 'varied': 2477,\n",
       " 'subject': 2248,\n",
       " 'plural': 1721,\n",
       " 'phrases': 1706,\n",
       " 'conjoined': 505,\n",
       " 'bride': 357,\n",
       " 'groom': 1033,\n",
       " 'definite': 627,\n",
       " 'descriptions': 655,\n",
       " 'numerically': 1562,\n",
       " 'quantified': 1855,\n",
       " 'path': 1660,\n",
       " 'ferreira': 927,\n",
       " 'mcclure': 1409,\n",
       " '1997': 21,\n",
       " 'traditional': 2386,\n",
       " 'anaphors': 183,\n",
       " 'antecedent': 194,\n",
       " 'discourse': 691,\n",
       " 'absent': 77,\n",
       " 'description': 654,\n",
       " 'parser': 1650,\n",
       " 'sensitive': 2077,\n",
       " 'constituent': 523,\n",
       " 'particular': 1657,\n",
       " 'reference': 1914,\n",
       " 'moxey': 1490,\n",
       " 'et': 817,\n",
       " 'al': 149,\n",
       " '2004': 29,\n",
       " 'automatically': 282,\n",
       " 'activates': 108,\n",
       " 'lexicon': 1330,\n",
       " 'answers': 193,\n",
       " 'ranged': 1867,\n",
       " 'listing': 1352,\n",
       " 'every': 823,\n",
       " 'storage': 2217,\n",
       " 'domain': 727,\n",
       " 'suffix': 2262,\n",
       " 'en': 783,\n",
       " 'occurs': 1578,\n",
       " 'high': 1070,\n",
       " 'plurals': 1723,\n",
       " 'mathematical': 1406,\n",
       " 'formalization': 966,\n",
       " 'parallel': 1646,\n",
       " 'dual': 739,\n",
       " 'route': 2033,\n",
       " 'race': 1860,\n",
       " 'reaction': 1878,\n",
       " 'essentially': 815,\n",
       " 'free': 982,\n",
       " 'parameter': 1647,\n",
       " 'speed': 2181,\n",
       " 'costly': 581,\n",
       " 'attribute': 273,\n",
       " 'ambiguity': 168,\n",
       " 'predominantly': 1761,\n",
       " 'verbal': 2488,\n",
       " 'ending': 790,\n",
       " 'third': 2350,\n",
       " 'contrasted': 552,\n",
       " 'nouns': 1558,\n",
       " 'surface': 2281,\n",
       " 'again': 141,\n",
       " 'solid': 2158,\n",
       " 'together': 2367,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the vocabulary\n",
    "tfidf.vocabulary_ # is the number the overall corpus frequency associated with each word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract: \"O4\"\n",
      "TF-IDF score: 0.000000\n",
      "  (0, 1983)\t0.07835154258702105\n",
      "  (0, 2023)\t0.07835154258702105\n",
      "  (0, 150)\t0.053564497424083576\n",
      "  (0, 197)\t0.07835154258702105\n",
      "  (0, 33)\t0.07835154258702105\n",
      "  (0, 1906)\t0.07074780697817605\n",
      "  (0, 607)\t0.07835154258702105\n",
      "  (0, 1845)\t0.07835154258702105\n",
      "  (0, 1289)\t0.06116823303292858\n",
      "  (0, 2410)\t0.03663291137378151\n",
      "  (0, 1571)\t0.05774913509840439\n",
      "  (0, 1807)\t0.041201585392734455\n",
      "  (0, 555)\t0.08374647885794773\n",
      "  (0, 1408)\t0.0562480846395736\n",
      "  (0, 1576)\t0.07416690491270024\n",
      "  (0, 2366)\t0.040345904593128395\n",
      "  (0, 2321)\t0.09135021446679273\n",
      "  (0, 1524)\t0.09135021446679273\n",
      "  (0, 2536)\t0.06314407136933106\n",
      "  (0, 1362)\t0.09135021446679273\n",
      "  (0, 1482)\t0.07835154258702105\n",
      "  (0, 677)\t0.1307057414144988\n",
      "  (0, 1102)\t0.09135021446679273\n",
      "  (0, 2523)\t0.034707825759721\n",
      "  (0, 2180)\t0.05014539948955939\n",
      "  :\t:\n",
      "  (94, 1590)\t0.172804509576423\n",
      "  (94, 2521)\t0.2434828720352746\n",
      "  (94, 1552)\t0.02994186966702364\n",
      "  (94, 2349)\t0.041681303328627\n",
      "  (94, 1233)\t0.04989083697013184\n",
      "  (94, 2410)\t0.034120484593007275\n",
      "  (94, 1408)\t0.05239037339260828\n",
      "  (94, 2366)\t0.037578826373216925\n",
      "  (94, 1254)\t0.05376317441292548\n",
      "  (94, 1771)\t0.0510959325571704\n",
      "  (94, 2333)\t0.05877789968163977\n",
      "  (94, 1589)\t0.028176028041900624\n",
      "  (94, 2332)\t0.12930971519112375\n",
      "  (94, 185)\t0.07515765274643385\n",
      "  (94, 1474)\t0.11512746381985019\n",
      "  (94, 1609)\t0.031093954718751923\n",
      "  (94, 2126)\t0.058813406674496825\n",
      "  (94, 2553)\t0.05376317441292548\n",
      "  (94, 2558)\t0.0638130357539575\n",
      "  (94, 2557)\t0.0638130357539575\n",
      "  (94, 1580)\t0.05350409097500943\n",
      "  (94, 1184)\t0.06320310523252423\n",
      "  (94, 2334)\t0.07133878796667924\n",
      "  (94, 1781)\t0.058813406674496825\n",
      "  (94, 1148)\t0.14720994072201898\n",
      "Column number:  2289\n"
     ]
    }
   ],
   "source": [
    "row = 5\n",
    "col = tfidf.vocabulary_['syllabifying'] # how is the tfidf matrix structured?\n",
    "\n",
    "print('Abstract: \"%s\"' % data.loc[row, 'ID'])\n",
    "print('TF-IDF score: %f' % matrix[row, col])\n",
    "\n",
    "print(matrix)\n",
    "matrix.shape\n",
    "\n",
    "print(\"Column number: \", col)\n",
    "\n",
    "# So clearly, the data is there now . . . we just need to extract the right data in the matrix to do the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 2586)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ====== pt. 2: importing the word2vec model and working with the dictionary file from the tf-idf =======\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6     \n",
      "0            the -0.242396  0.136115  0.176884 -0.106608 -0.111945  0.008947  \\\n",
      "1             of -0.191138  0.168684  0.132903 -0.099730 -0.113432 -0.022978   \n",
      "2            and -0.216545  0.155390  0.071324 -0.070429 -0.159644 -0.038712   \n",
      "3             in -0.227537  0.125394  0.097702 -0.155055 -0.133572  0.052193   \n",
      "4             to -0.257741  0.174983  0.165620 -0.139889 -0.098801 -0.049469   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "275556  workover  0.394763 -0.138997 -0.243322 -0.157992 -0.094953  0.127140   \n",
      "275557  condotel -0.091486  0.510353  0.115290 -0.514122 -0.335069  0.128298   \n",
      "275558    kuntey -0.232415  0.054326  0.415971 -0.029960  0.161247  0.246369   \n",
      "275559     houga  0.211834 -0.092607 -0.048265  0.064677  0.064417 -0.145476   \n",
      "275560    gp-stn -0.207188  0.077137  0.205872 -0.182772  0.243247  0.688170   \n",
      "\n",
      "             7         8         9    ...       191       192       193   \n",
      "0       0.135947 -0.082421  0.085838  ...  0.148953  0.064447 -0.001178  \\\n",
      "1       0.174045 -0.097945  0.046131  ...  0.089066  0.083751 -0.024087   \n",
      "2       0.064945 -0.013719  0.036322  ...  0.112115  0.035288 -0.061588   \n",
      "3       0.143991 -0.084266  0.066472  ...  0.125955  0.089060 -0.217870   \n",
      "4       0.122077 -0.031022  0.049582  ...  0.215590 -0.073144 -0.058039   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "275556  0.164249  0.024907 -0.035865  ...  0.513726  0.096588 -0.140386   \n",
      "275557  0.045652 -0.089612 -0.234540  ...  0.305439 -0.319811  0.252723   \n",
      "275558  0.131067 -0.145976  0.226713  ...  0.021065 -0.280798 -0.324447   \n",
      "275559  0.251887 -0.283335  0.474550  ...  0.188981  0.178981 -0.070167   \n",
      "275560  0.201276 -0.065501 -0.015827  ...  0.035363 -0.065787  0.152879   \n",
      "\n",
      "             194       195       196       197       198       199       200  \n",
      "0      -0.016101 -0.088447  0.021496 -0.059557  0.005552 -0.032828 -0.071551  \n",
      "1      -0.012805 -0.125353  0.010637 -0.118226  0.060810  0.001252 -0.073941  \n",
      "2      -0.004658 -0.107913  0.038720 -0.011822  0.065564  0.042976 -0.112689  \n",
      "3      -0.011854 -0.141282  0.020798 -0.082806 -0.056006 -0.044313 -0.163796  \n",
      "4      -0.070486 -0.115184  0.083460  0.000925  0.015039 -0.131154 -0.144334  \n",
      "...          ...       ...       ...       ...       ...       ...       ...  \n",
      "275556  0.167050 -0.310451 -0.135193 -0.152563 -0.139502  0.006745 -0.240002  \n",
      "275557  0.238032 -0.227958  0.048799  0.309579  0.033845  0.223744 -0.342862  \n",
      "275558  0.076553 -0.021072 -0.260636  0.222612 -0.362702  0.357780  0.081833  \n",
      "275559 -0.129690 -0.090388 -0.148845  0.259977  0.027815  0.047239  0.126365  \n",
      "275560  0.038332 -0.137882  0.274136 -0.291676 -0.071298 -0.380950 -0.393761  \n",
      "\n",
      "[275561 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importing the word2vec model as dataframe:\n",
    "\n",
    "model = '/Users/christianstenbro/AU/Applied_Cognitive_Science/Rep_rep_project/prediction_models/data and code/mag_200d_psy_eco_word2vec'\n",
    "\n",
    "model = pd.read_csv(model, sep=' ', skiprows = 1, header=None)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              the\n",
      "1               of\n",
      "2              and\n",
      "3               in\n",
      "4               to\n",
      "            ...   \n",
      "275556    workover\n",
      "275557    condotel\n",
      "275558      kuntey\n",
      "275559       houga\n",
      "275560      gp-stn\n",
      "Name: 0, Length: 275561, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(model.iloc[:,0]) # this is the column of works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0     1\n",
      "0              in  1148\n",
      "1        previous  1781\n",
      "2         studies  2243\n",
      "3         english   793\n",
      "4       examining   835\n",
      "...           ...   ...\n",
      "2581   phonologic  1698\n",
      "2582          yes  2575\n",
      "2583         _obe    67\n",
      "2584  constitutes   526\n",
      "2585   misleading  1448\n",
      "\n",
      "[2586 rows x 2 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Defining dictionary as a data frame\n",
    "\n",
    "# First, use dict.items() to get a group of the key-value pairs in the dictionary:\n",
    "\n",
    "items = dict.items(tfidf.vocabulary_)\n",
    "\n",
    "# Then, having this group as an object, use list(obj) to convert it to a list:\n",
    "\n",
    "items = list(items)\n",
    "\n",
    "# Finally, using this list as data, call numpy.array(data) to convert it to an array. But actually I want it to be a core pd data frame:\n",
    "\n",
    "dict_df = pd.DataFrame(items)\n",
    "\n",
    "print(dict_df)\n",
    "\n",
    "print(type(dict_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             keys  values\n",
      "0              in    1148\n",
      "1        previous    1781\n",
      "2         studies    2243\n",
      "3         english     793\n",
      "4       examining     835\n",
      "...           ...     ...\n",
      "2581   phonologic    1698\n",
      "2582          yes    2575\n",
      "2583         _obe      67\n",
      "2584  constitutes     526\n",
      "2585   misleading    1448\n",
      "\n",
      "[2586 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Renaming columns:\n",
    "\n",
    "dict_df.columns = ['keys', 'values']\n",
    "\n",
    "print(dict_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      values         keys\n",
      "0       1148           in\n",
      "1       1781     previous\n",
      "2       2243      studies\n",
      "3        793      english\n",
      "4        835    examining\n",
      "...      ...          ...\n",
      "2581    1698   phonologic\n",
      "2582    2575          yes\n",
      "2583      67         _obe\n",
      "2584     526  constitutes\n",
      "2585    1448   misleading\n",
      "\n",
      "[2586 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# . . . and flipping the order:\n",
    "\n",
    "column_titles = ['values', 'keys']\n",
    "dict_df = dict_df.reindex(columns = column_titles)\n",
    "print(dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keys</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>previous</td>\n",
       "      <td>1781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>studies</td>\n",
       "      <td>2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>examining</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>phonologic</td>\n",
       "      <td>1698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>yes</td>\n",
       "      <td>2575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>_obe</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>constitutes</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>misleading</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2586 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             keys  values\n",
       "0              in    1148\n",
       "1        previous    1781\n",
       "2         studies    2243\n",
       "3         english     793\n",
       "4       examining     835\n",
       "...           ...     ...\n",
       "2581   phonologic    1698\n",
       "2582          yes    2575\n",
       "2583         _obe      67\n",
       "2584  constitutes     526\n",
       "2585   misleading    1448\n",
       "\n",
       "[2586 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can index from the dataframe:\n",
    "\n",
    "dict_df['keys'] # either extracting the entire column\n",
    "dict_df['keys'][4] # or a single entry in a column\n",
    "dict_df[['keys', 'values']] # how would I extract and entire row with data from both columns though?\n",
    "\n",
    "# Link to indexing tips in Python: https://www.dataquest.io/blog/tutorial-indexing-dataframes-in-pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['values', 'keys'], dtype='object')\n",
      "RangeIndex(start=0, stop=2586, step=1)\n"
     ]
    }
   ],
   "source": [
    "# Examining some attribrutes of the data:\n",
    "\n",
    "print(dict_df.columns)\n",
    "print(dict_df.index) # this is useful knowledge when wanting to construct the for loop\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task is to remove the words from the word2vec model (model) that do not appear in the dictionary (dict_df) and create a new model data-frame.\n",
    "\n",
    "- One way to do this is by making a for-loop which goes through each row of our model dataframe, checking if there is a match with any of the words in the dictionaries. \n",
    "\n",
    "- If there is a match, the **word and its associated vector of dimensional values** should be added to a new two-column data-frame. \n",
    "\n",
    "- Ultimately, this data-frame will be as long as the dictionary, which should mean that it will be commensurable with the tf-idf matrix (elaborate).\n",
    "\n",
    "> Make a plan for how to concretely design the for loop. Remember that we need to loop through the word2vec model for each word entry (row) in our dict_df!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              the\n",
       "1               of\n",
       "2              and\n",
       "3               in\n",
       "4               to\n",
       "            ...   \n",
       "275556    workover\n",
       "275557    condotel\n",
       "275558      kuntey\n",
       "275559       houga\n",
       "275560      gp-stn\n",
       "Name: 0, Length: 275561, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df.shape\n",
    "model.shape\n",
    "\n",
    "model.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Matches:\n",
      "                   Term  Value\n",
      "0          syllabifying   2289\n",
      "1              grosjean   1034\n",
      "2       whethersubjects   2540\n",
      "3              thiscase   2352\n",
      "4             wordswere   2559\n",
      "..                  ...    ...\n",
      "80                 _eap     63\n",
      "81  feedbackconsistency    920\n",
      "82                  _ip     65\n",
      "83                  _ob     66\n",
      "84                 _obe     67\n",
      "\n",
      "[85 rows x 2 columns]\n",
      "Matched Data Frame:\n",
      "              0         1         2         3         4         5         6     \n",
      "0              in -0.227537  0.125394  0.097702 -0.155055 -0.133572  0.052193  \\\n",
      "1        previous -0.346380  0.006304  0.305970 -0.139675 -0.182512  0.049250   \n",
      "2         studies -0.249250  0.010476  0.088974 -0.260289 -0.054414 -0.030271   \n",
      "3         english -0.157916  0.097971  0.137283 -0.171298  0.103821  0.091728   \n",
      "4       examining -0.314322  0.109868  0.144253 -0.049473 -0.119032 -0.173928   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "2580        globe -0.021529 -0.040331  0.093697  0.071710  0.295056 -0.512503   \n",
      "2581   phonologic  0.166119  0.011583  0.617321  0.059052 -0.167412  0.449738   \n",
      "2582          yes -0.035224 -0.060090  0.592755 -0.317422 -0.246039  0.318855   \n",
      "2584  constitutes -0.191645  0.074492  0.268575 -0.336695 -0.071241 -0.189615   \n",
      "2585   misleading -0.356981 -0.131151  0.376909 -0.188344 -0.202470  0.300605   \n",
      "\n",
      "           7         8         9    ...       191       192       193   \n",
      "0     0.143991 -0.084266  0.066472  ...  0.125955  0.089060 -0.217870  \\\n",
      "1     0.182775 -0.317705  0.238295  ...  0.125932 -0.114897 -0.025431   \n",
      "2     0.194103 -0.325225  0.160901  ...  0.087359 -0.130020 -0.146982   \n",
      "3     0.227996 -0.237087  0.038814  ...  0.054863  0.129875 -0.239072   \n",
      "4     0.266191 -0.290743  0.030236  ...  0.061207 -0.060738 -0.196720   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2580  0.023171  0.033605  0.056809  ...  0.131217  0.100842 -0.334557   \n",
      "2581  0.174121  0.070267  0.134964  ... -0.254067 -0.242696  0.105087   \n",
      "2582  0.028493  0.371991  0.457179  ... -0.386318  0.015517  0.234608   \n",
      "2584  0.052777 -0.034520 -0.013880  ...  0.228042  0.233316 -0.016832   \n",
      "2585  0.007481  0.193716  0.441165  ... -0.095932 -0.173330  0.062536   \n",
      "\n",
      "           194       195       196       197       198       199       200  \n",
      "0    -0.011854 -0.141282  0.020798 -0.082806 -0.056006 -0.044313 -0.163796  \n",
      "1     0.251213 -0.250936 -0.024032  0.100205  0.017044  0.066197  0.045374  \n",
      "2     0.124166 -0.426162 -0.074545  0.017245 -0.096232 -0.001212 -0.059817  \n",
      "3     0.025619  0.082328  0.073301  0.082712  0.122293  0.147350 -0.081697  \n",
      "4     0.074695 -0.264687 -0.032342 -0.036688  0.044775  0.161296 -0.184259  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2580  0.247142  0.097800 -0.080029 -0.135338 -0.150630  0.090382 -0.302848  \n",
      "2581  0.125844 -0.480237 -0.319941 -0.040487 -0.627847 -0.033238 -0.188857  \n",
      "2582  0.019007 -0.049388 -0.146896  0.577466  0.029020  0.323428 -0.002132  \n",
      "2584  0.101470 -0.230295  0.158561 -0.253239 -0.000294  0.102868 -0.145611  \n",
      "2585  0.115911 -0.243182 -0.190490  0.375547  0.047946  0.121369 -0.308563  \n",
      "\n",
      "[2501 rows x 201 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying out a for loop to extract terms from the model: \n",
    "\n",
    "# data 1 = dict_df \n",
    "# data 2 = model\n",
    "\n",
    "# First we create an empty data frame to store the matched rows from the model\n",
    "matched_df = pd.DataFrame(columns = model.columns)\n",
    "\n",
    "# Then we create an empty dataframe to store the missing matches\n",
    "missing_matches = pd.DataFrame(columns=['Term', 'Value'])\n",
    "\n",
    "# We iterate through each term in the model:\n",
    "for i, term in enumerate(dict_df['keys']):\n",
    "    # Checking if the terms exists in the dictionary\n",
    "    if term in model.iloc[:,0].values:\n",
    "        # If there is a match, we extract the entire row from the model and add it to the matched_df\n",
    "        row = model.loc[model.iloc[:,0] == term] # is this extracting the row?\n",
    "        row.index = [i]\n",
    "        matched_df = pd.concat([matched_df, row]) # how does this line work?\n",
    "    else:\n",
    "        # If no match is found, add the term to missing_matches\n",
    "        missing_matches.loc[len(missing_matches)] = [term, dict_df.iloc[i, 0]]\n",
    "\n",
    "matched_df = matched_df.sort_index()    \n",
    "\n",
    "# Print missing matches\n",
    "print(\"Missing Matches:\")\n",
    "print(missing_matches)\n",
    "\n",
    "# Print the matched data frame\n",
    "print(\"Matched Data Frame:\")\n",
    "print(matched_df)\n",
    "\n",
    "type(matched_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1148\n",
       "1       1781\n",
       "2       2243\n",
       "3        793\n",
       "4        835\n",
       "        ... \n",
       "2581    1698\n",
       "2582    2575\n",
       "2583      67\n",
       "2584     526\n",
       "2585    1448\n",
       "Name: values, Length: 2586, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>-0.227537</td>\n",
       "      <td>0.125394</td>\n",
       "      <td>0.097702</td>\n",
       "      <td>-0.155055</td>\n",
       "      <td>-0.133572</td>\n",
       "      <td>0.052193</td>\n",
       "      <td>0.143991</td>\n",
       "      <td>-0.084266</td>\n",
       "      <td>0.066472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125955</td>\n",
       "      <td>0.089060</td>\n",
       "      <td>-0.217870</td>\n",
       "      <td>-0.011854</td>\n",
       "      <td>-0.141282</td>\n",
       "      <td>0.020798</td>\n",
       "      <td>-0.082806</td>\n",
       "      <td>-0.056006</td>\n",
       "      <td>-0.044313</td>\n",
       "      <td>-0.163796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>previous</td>\n",
       "      <td>-0.346380</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>-0.139675</td>\n",
       "      <td>-0.182512</td>\n",
       "      <td>0.049250</td>\n",
       "      <td>0.182775</td>\n",
       "      <td>-0.317705</td>\n",
       "      <td>0.238295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125932</td>\n",
       "      <td>-0.114897</td>\n",
       "      <td>-0.025431</td>\n",
       "      <td>0.251213</td>\n",
       "      <td>-0.250936</td>\n",
       "      <td>-0.024032</td>\n",
       "      <td>0.100205</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>0.066197</td>\n",
       "      <td>0.045374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>studies</td>\n",
       "      <td>-0.249250</td>\n",
       "      <td>0.010476</td>\n",
       "      <td>0.088974</td>\n",
       "      <td>-0.260289</td>\n",
       "      <td>-0.054414</td>\n",
       "      <td>-0.030271</td>\n",
       "      <td>0.194103</td>\n",
       "      <td>-0.325225</td>\n",
       "      <td>0.160901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087359</td>\n",
       "      <td>-0.130020</td>\n",
       "      <td>-0.146982</td>\n",
       "      <td>0.124166</td>\n",
       "      <td>-0.426162</td>\n",
       "      <td>-0.074545</td>\n",
       "      <td>0.017245</td>\n",
       "      <td>-0.096232</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>-0.059817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>-0.157916</td>\n",
       "      <td>0.097971</td>\n",
       "      <td>0.137283</td>\n",
       "      <td>-0.171298</td>\n",
       "      <td>0.103821</td>\n",
       "      <td>0.091728</td>\n",
       "      <td>0.227996</td>\n",
       "      <td>-0.237087</td>\n",
       "      <td>0.038814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054863</td>\n",
       "      <td>0.129875</td>\n",
       "      <td>-0.239072</td>\n",
       "      <td>0.025619</td>\n",
       "      <td>0.082328</td>\n",
       "      <td>0.073301</td>\n",
       "      <td>0.082712</td>\n",
       "      <td>0.122293</td>\n",
       "      <td>0.147350</td>\n",
       "      <td>-0.081697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>examining</td>\n",
       "      <td>-0.314322</td>\n",
       "      <td>0.109868</td>\n",
       "      <td>0.144253</td>\n",
       "      <td>-0.049473</td>\n",
       "      <td>-0.119032</td>\n",
       "      <td>-0.173928</td>\n",
       "      <td>0.266191</td>\n",
       "      <td>-0.290743</td>\n",
       "      <td>0.030236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061207</td>\n",
       "      <td>-0.060738</td>\n",
       "      <td>-0.196720</td>\n",
       "      <td>0.074695</td>\n",
       "      <td>-0.264687</td>\n",
       "      <td>-0.032342</td>\n",
       "      <td>-0.036688</td>\n",
       "      <td>0.044775</td>\n",
       "      <td>0.161296</td>\n",
       "      <td>-0.184259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \n",
       "0         in -0.227537  0.125394  0.097702 -0.155055 -0.133572  0.052193  \\\n",
       "1   previous -0.346380  0.006304  0.305970 -0.139675 -0.182512  0.049250   \n",
       "2    studies -0.249250  0.010476  0.088974 -0.260289 -0.054414 -0.030271   \n",
       "3    english -0.157916  0.097971  0.137283 -0.171298  0.103821  0.091728   \n",
       "4  examining -0.314322  0.109868  0.144253 -0.049473 -0.119032 -0.173928   \n",
       "\n",
       "        7         8         9    ...       191       192       193       194   \n",
       "0  0.143991 -0.084266  0.066472  ...  0.125955  0.089060 -0.217870 -0.011854  \\\n",
       "1  0.182775 -0.317705  0.238295  ...  0.125932 -0.114897 -0.025431  0.251213   \n",
       "2  0.194103 -0.325225  0.160901  ...  0.087359 -0.130020 -0.146982  0.124166   \n",
       "3  0.227996 -0.237087  0.038814  ...  0.054863  0.129875 -0.239072  0.025619   \n",
       "4  0.266191 -0.290743  0.030236  ...  0.061207 -0.060738 -0.196720  0.074695   \n",
       "\n",
       "        195       196       197       198       199       200  \n",
       "0 -0.141282  0.020798 -0.082806 -0.056006 -0.044313 -0.163796  \n",
       "1 -0.250936 -0.024032  0.100205  0.017044  0.066197  0.045374  \n",
       "2 -0.426162 -0.074545  0.017245 -0.096232 -0.001212 -0.059817  \n",
       "3  0.082328  0.073301  0.082712  0.122293  0.147350 -0.081697  \n",
       "4 -0.264687 -0.032342 -0.036688  0.044775  0.161296 -0.184259  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1148</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1781</td>\n",
       "      <td>previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2243</td>\n",
       "      <td>studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>793</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>835</td>\n",
       "      <td>examining</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   values       keys\n",
       "0    1148         in\n",
       "1    1781   previous\n",
       "2    2243    studies\n",
       "3     793    english\n",
       "4     835  examining"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ========== next step: remove missing words from TF_IDF matrix ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing matches list dimensions:  (85, 2)\n",
      "Dimensions of the new model data frame:  (2501, 201)\n",
      "Dimensions of the TF-IDF matrix:  (95, 2586)\n"
     ]
    }
   ],
   "source": [
    "# Checking some dimensions of the objects of interest:\n",
    "\n",
    "print(\"Missing matches list dimensions: \", missing_matches.shape)\n",
    "print(\"Dimensions of the new model data frame: \", matched_df.shape)\n",
    "print(\"Dimensions of the TF-IDF matrix: \", matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Term  Value\n",
      "0          syllabifying   2289\n",
      "1              grosjean   1034\n",
      "2       whethersubjects   2540\n",
      "3              thiscase   2352\n",
      "4             wordswere   2559\n",
      "..                  ...    ...\n",
      "80                 _eap     63\n",
      "81  feedbackconsistency    920\n",
      "82                  _ip     65\n",
      "83                  _ob     66\n",
      "84                 _obe     67\n",
      "\n",
      "[85 rows x 2 columns]\n",
      "values         1350\n",
      "keys      listeners\n",
      "Name: 164, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(missing_matches)\n",
    "# print(missing_matches['Index'])\n",
    "\n",
    "print(dict_df.iloc[164, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the matching_df as csv and sending to emil\n",
    "\n",
    "from pathlib import Path  \n",
    "filepath = Path('/Users/christianstenbro/Programming/ripley_project/Data_files/matching_df.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "matched_df.to_csv(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflection pad:\n",
    "\n",
    "- We want to modify the for loop creating the matched_df to also output the index for the missing matches\n",
    "\n",
    "- Then, we can use this information to remove the corresponding columns from the TF-IDF\n",
    "\n",
    "**FINALLY** we are ready to somehow (?) multiply the two matrices. \n",
    "\n",
    "- We want the output to have one number for each abstract - that's all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2289\n",
       "1     1034\n",
       "2     2540\n",
       "3     2352\n",
       "4     2559\n",
       "      ... \n",
       "80      63\n",
       "81     920\n",
       "82      65\n",
       "83      66\n",
       "84      67\n",
       "Name: Value, Length: 85, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_matches['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2289, 1034, 2540, 2352, 2559, 411, 2364, 1757, 1076, 1852, 1661, 34, 53, 62, 1697, 926, 2288, 1957, 1263, 2469, 1261, 2506, 1490, 798, 1479, 1447, 1337, 2194, 235, 237, 970, 2577, 2486, 2374, 657, 901, 1084, 1620, 2482, 1583, 756, 755, 2483, 754, 161, 322, 1098, 1099, 1503, 2255, 2443, 2052, 1861, 2190, 1075, 1290, 878, 2489, 1319, 1540, 1592, 2335, 346, 2070, 2189, 1024, 344, 603, 724, 2188, 1666, 2378, 1338, 2227, 2228, 1097, 1096, 1638, 1581, 64, 63, 920, 65, 66, 67]\n"
     ]
    }
   ],
   "source": [
    "# Converting the TF-IDF matrix to panda pd\n",
    "\n",
    "tf_idf_df = pd.DataFrame.sparse.from_spmatrix(matrix)\n",
    "\n",
    "#print(tf_idf_df.shape)\n",
    "\n",
    "# Removing the columns contained in the missing_matches['Value']\n",
    "\n",
    "# Converting missing_matches['Value']\n",
    "\n",
    "type(missing_matches['Value'])\n",
    "\n",
    "missing_matches_list = list(missing_matches['Value'])\n",
    "print(missing_matches_list)\n",
    "\n",
    "# Sort tf-idf matrix and remove the columns corresponding to the values contained in the missing_matches list:\n",
    "\n",
    "tf_idf_matched_df = tf_idf_df[tf_idf_df.columns[~tf_idf_df.columns.isin(missing_matches_list)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf_idf_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===== Reindexing and alligning matrices ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4         5         6     \n",
      "0    -0.227537  0.125394  0.097702 -0.155055 -0.133572  0.052193  0.143991  \\\n",
      "1    -0.346380  0.006304  0.305970 -0.139675 -0.182512  0.049250  0.182775   \n",
      "2    -0.249250  0.010476  0.088974 -0.260289 -0.054414 -0.030271  0.194103   \n",
      "3    -0.157916  0.097971  0.137283 -0.171298  0.103821  0.091728  0.227996   \n",
      "4    -0.314322  0.109868  0.144253 -0.049473 -0.119032 -0.173928  0.266191   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2496 -0.021529 -0.040331  0.093697  0.071710  0.295056 -0.512503  0.023171   \n",
      "2497  0.166119  0.011583  0.617321  0.059052 -0.167412  0.449738  0.174121   \n",
      "2498 -0.035224 -0.060090  0.592755 -0.317422 -0.246039  0.318855  0.028493   \n",
      "2499 -0.191645  0.074492  0.268575 -0.336695 -0.071241 -0.189615  0.052777   \n",
      "2500 -0.356981 -0.131151  0.376909 -0.188344 -0.202470  0.300605  0.007481   \n",
      "\n",
      "           7         8         9    ...       190       191       192   \n",
      "0    -0.084266  0.066472  0.047409  ...  0.125955  0.089060 -0.217870  \\\n",
      "1    -0.317705  0.238295  0.004515  ...  0.125932 -0.114897 -0.025431   \n",
      "2    -0.325225  0.160901  0.054957  ...  0.087359 -0.130020 -0.146982   \n",
      "3    -0.237087  0.038814 -0.321406  ...  0.054863  0.129875 -0.239072   \n",
      "4    -0.290743  0.030236 -0.013335  ...  0.061207 -0.060738 -0.196720   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2496  0.033605  0.056809  0.362343  ...  0.131217  0.100842 -0.334557   \n",
      "2497  0.070267  0.134964  0.014066  ... -0.254067 -0.242696  0.105087   \n",
      "2498  0.371991  0.457179  0.204451  ... -0.386318  0.015517  0.234608   \n",
      "2499 -0.034520 -0.013880  0.109261  ...  0.228042  0.233316 -0.016832   \n",
      "2500  0.193716  0.441165  0.099004  ... -0.095932 -0.173330  0.062536   \n",
      "\n",
      "           193       194       195       196       197       198       199  \n",
      "0    -0.011854 -0.141282  0.020798 -0.082806 -0.056006 -0.044313 -0.163796  \n",
      "1     0.251213 -0.250936 -0.024032  0.100205  0.017044  0.066197  0.045374  \n",
      "2     0.124166 -0.426162 -0.074545  0.017245 -0.096232 -0.001212 -0.059817  \n",
      "3     0.025619  0.082328  0.073301  0.082712  0.122293  0.147350 -0.081697  \n",
      "4     0.074695 -0.264687 -0.032342 -0.036688  0.044775  0.161296 -0.184259  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2496  0.247142  0.097800 -0.080029 -0.135338 -0.150630  0.090382 -0.302848  \n",
      "2497  0.125844 -0.480237 -0.319941 -0.040487 -0.627847 -0.033238 -0.188857  \n",
      "2498  0.019007 -0.049388 -0.146896  0.577466  0.029020  0.323428 -0.002132  \n",
      "2499  0.101470 -0.230295  0.158561 -0.253239 -0.000294  0.102868 -0.145611  \n",
      "2500  0.115911 -0.243182 -0.190490  0.375547  0.047946  0.121369 -0.308563  \n",
      "\n",
      "[2501 rows x 200 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reindexing the 'matched' word2vec dataframe\n",
    "\n",
    "word2vec_rindx = matched_df.iloc[:, 1:] # Removing the first column (with the actual words)\n",
    "word2vec_rindx = word2vec_rindx.reset_index(drop = True) # Reindexing\n",
    "word2vec_rindx.columns = range(len(word2vec_rindx.columns)) # . . . and changing the index range to 0-199\n",
    "\n",
    "print(word2vec_rindx)\n",
    "type(word2vec_rindx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     1     2     3     4     5     6     7     8     9     ...      2575   \n",
      "0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000  \\\n",
      "1    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "2    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "3    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "4    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...       ...   \n",
      "90   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "91   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "92   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "93   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "94   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.085085   \n",
      "\n",
      "    2576  2578  2579  2580  2581  2582  2583  2584  2585  \n",
      "0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "..   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "90   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "91   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "92   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "93   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "94   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[95 rows x 2501 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing the same for the tf_idf.matched dataframe:\n",
    "\n",
    "tf_idf_rindx = tf_idf_matched_df.reset_index(drop = True) # Reindexing\n",
    "tf_idf_rindx.reset_index(drop = True, inplace = True) # . . . and changing the index range to 0-199\n",
    "\n",
    "print(tf_idf_rindx)\n",
    "type(tf_idf_rindx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the TF-IDF dataframe:  (95, 2501)\n",
      "Type of TF-IDF dataframe:  <class 'pandas.core.frame.DataFrame'>\n",
      " \n",
      "Dimensions of the word2vec dataframe:  (2501, 200)\n",
      "Type of word2vec dataframe:  <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Checking type and dimensions of our two dataframes:\n",
    "\n",
    "print(\"Dimensions of the TF-IDF dataframe: \", tf_idf_rindx.shape)\n",
    "print(\"Type of TF-IDF dataframe: \", type(tf_idf_rindx))\n",
    "print(\" \")\n",
    "print(\"Dimensions of the word2vec dataframe: \", word2vec_rindx.shape)\n",
    "print(\"Type of word2vec dataframe: \", type(word2vec_rindx))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======= Multiplying the matrices: TF-IDF x Word2Vec ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# For matrices to be commensurable in a multiplication: \n",
    "# X * Y, the number of columns of X needs to correspond to the number of rows in Y\n",
    "\n",
    "# Fortunately, the number of colums in the TF-IDF dataframe (98, 2510) is the same as the\n",
    "# as the number of rows in the word2vec dataframe (2510, 200). \n",
    "\n",
    "# Mathematically, it should not be a problem to multiply the two:\n",
    "\n",
    "#product = tf_idf_rindx.dot(word2vec_rindx) \n",
    "# This does not work. We can try to use numpy?\n",
    "\n",
    "print(type(tf_idf_rindx))\n",
    "\n",
    "tf_idf_rindx_np = tf_idf_rindx.to_numpy() # Remember this parenthesis!\n",
    "\n",
    "print(type(tf_idf_rindx_np))\n",
    "\n",
    "word2vec_rindx_np = word2vec_rindx.to_numpy()\n",
    "\n",
    "print(type(word2vec_rindx_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product shape:  (95, 200) Product type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Re-attempting the multiplication with numpy methods: \n",
    "\n",
    "tf_idf_w2v_product = np.matmul(tf_idf_rindx_np, word2vec_rindx_np)\n",
    "\n",
    "print(\"Product shape: \", tf_idf_w2v_product.shape, \"Product type: \", type(tf_idf_w2v_product))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====== Status update ======="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a similar matrix, using tf instead of tf_idf:\n",
    "\n",
    "    - Everything should be the same, only the input matrix should contain pure tf's instead of tf-idf's\n",
    "    \n",
    "    - We can reuse the script from pt. 1 and change one command?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-matrix dimensions:  (95, 2586) TF-matrix object type:  <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# 1. Computing term frequencies:\n",
    "\n",
    "# data_file = '/Users/christianstenbro/Programming/ripley_project/Data_files/original_paper_data_frame_cleaned_v1.csv'\n",
    "# data = pd.read_csv(data_file, sep=',', names=['ID', 'bib', 'abstract', 'rep_score'])\n",
    "# data.head()\n",
    "\n",
    "vectorizer = CountVectorizer() # The CountVectorizer converts a text corpus (here our collection of abstracts in 'data) to a matrix of 'token counts' = term frequencies (tf).\n",
    "matrix_tf = vectorizer.fit_transform(data['abstract'].values.astype('U'))\n",
    "\n",
    "print(\"TF-matrix dimensions: \", matrix_tf.shape, \"TF-matrix object type: \", type(matrix_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the vocabularies of the tf and tfidf matrices identical? Output: True\n"
     ]
    }
   ],
   "source": [
    "vectorizer.vocabulary_ # And this matches the vocab of the tf_idf matrix:\n",
    "\n",
    "print(\"Are the vocabularies of the tf and tfidf matrices identical? Output:\", vectorizer.vocabulary_ == tfidf.vocabulary_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we can use the exact same methods to process the tf-matrix as we already used for the tf-idf matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of tf_matched_df:  (95, 2501)\n"
     ]
    }
   ],
   "source": [
    "# We already have the missing matches list from previously:\n",
    "\n",
    "missing_matches_list # The column index for the terms in the abstract matrix not present in the word2vec model. \n",
    "# These will be extracted from the tf-matrix as well to make it commensurable with the word2vec model matrix:\n",
    "\n",
    "# First, we convert the tf-matrix from a sparse matrix to a pd.DataFrame:\n",
    "\n",
    "tf_df = pd.DataFrame.sparse.from_spmatrix(matrix_tf)\n",
    "\n",
    "# Then we remove the columns correponding to the missing words in the word2vec model:\n",
    "\n",
    "tf_matched_df = tf_df[tf_df.columns[~tf_df.columns.isin(missing_matches_list)]]\n",
    "\n",
    "print(\"Dimensions of tf_matched_df: \", tf_matched_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we reindex the dataframe and convert it to a numpy array:\n",
    "\n",
    "tf_rindx = tf_matched_df.reset_index(drop = True) # Reindexing\n",
    "tf_rindx.reset_index(drop = True, inplace = True) # . . . and changing the index range to 0-199\n",
    "\n",
    "# print(tf_rindx) # One wonders if it actually contains any numbers?\n",
    "# type(tf_rindx)\n",
    "\n",
    "tf_rindx_np = tf_rindx.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the TF dataframe:  (95, 2501)\n",
      "Type of TF dataframe:  <class 'numpy.ndarray'>\n",
      " \n",
      "Dimensions of the word2vec dataframe:  (2501, 200)\n",
      "Type of word2vec dataframe:  <class 'numpy.ndarray'>\n",
      " \n",
      "Are the matrices commensurable? Output: True\n"
     ]
    }
   ],
   "source": [
    "# Again, we can check if the matrices are commensurable: \n",
    "\n",
    "print(\"Dimensions of the TF dataframe: \", tf_rindx_np.shape)\n",
    "print(\"Type of TF dataframe: \", type(tf_rindx_np))\n",
    "print(\" \")\n",
    "print(\"Dimensions of the word2vec dataframe: \", word2vec_rindx_np.shape)\n",
    "print(\"Type of word2vec dataframe: \", type(word2vec_rindx_np))\n",
    "print(\" \")\n",
    "print(\"Are the matrices commensurable? Output:\", len(tf_rindx_np[0]) == len(word2vec_rindx_np))\n",
    "\n",
    "# print(len(tf_rindx_np[0])) # Strange way of finding the column and row numbers, at least compared to R. \n",
    "# print(len(word2vec_rindx_np))\n",
    "\n",
    "# Notice that 'array[0]' is the second dimension of the array while (columns), while 'array' is simply the first dimension (rows)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====== Multiplying matrices: TF x Word2Vec ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product shape:  (95, 200) Product type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# With everything in place, we can multiply the matrices using the np.matmul function: \n",
    "\n",
    "tf_w2v_product = np.matmul(tf_rindx_np, word2vec_rindx_np)\n",
    "\n",
    "print(\"Product shape: \", tf_w2v_product.shape, \"Product type: \", type(tf_w2v_product))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have our two matrices.\n",
    "\n",
    "But how do we actually conceptualize what these matrices consist of?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==== Appending ground truth encodings ======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes' 'partial' 'partial' 'yes' 'no' 'no' 'yes' 'yes' 'yes' 'yes' 'yes'\n",
      " 'yes' 'yes' 'no' 'yes' 'yes' 'partial' 'yes' 'yes' 'yes' 'yes' 'yes'\n",
      " 'yes' 'yes' 'yes' 'partial' 'yes' 'yes' 'no' 'no' 'yes' 'yes' 'partial'\n",
      " 'yes' 'yes' 'partial' 'yes' 'no' 'no' 'yes' 'no' 'partial' 'yes' 'yes'\n",
      " 'yes' 'yes' 'yes' 'yes' 'partial' 'no' 'partial' 'yes' 'yes' 'yes' 'yes'\n",
      " 'yes' 'yes' 'no' 'no' 'no' 'yes' 'partial' 'partial' 'yes' 'yes' 'no'\n",
      " 'yes' 'yes' 'yes' 'no' 'yes' 'yes' 'yes' 'yes' 'yes' 'partial' 'no' 'no'\n",
      " 'no' 'yes' 'yes' 'no' 'yes' 'no' 'no' 'yes' 'partial' 'partial' 'yes'\n",
      " 'yes' 'yes' 'no' 'no' 'yes' 'yes']\n"
     ]
    }
   ],
   "source": [
    "# Create columns of replication outcomes from data_set:\n",
    "\n",
    "rep_column = (data['rep_score'])\n",
    "\n",
    "rep_column = rep_column.to_numpy()\n",
    "\n",
    "print(rep_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1\n",
      " 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1\n",
      " 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1]\n",
      "(95,)\n"
     ]
    }
   ],
   "source": [
    "# Creating a for loop replacing the 'yes/partial' with 1 and 'no' with 0 to obtain a binary outcome variable:\n",
    "\n",
    "for i, val in enumerate(rep_column):\n",
    "    if val == \"yes\" or i == \"partial\":\n",
    "        rep_column[i] = 1\n",
    "    else:\n",
    "        rep_column[i] = 0\n",
    "\n",
    "print(rep_column)\n",
    "print(rep_column.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append outcomes to tf-idf * w2v product matrix:\n",
    "\n",
    "tf_idf_w2v_encoded = np.c_[ tf_idf_w2v_product, rep_column ]\n",
    "\n",
    "tf_idf_w2v_encoded.shape\n",
    "\n",
    "tf_idf_w2v_encoded = pd.DataFrame(tf_idf_w2v_encoded)\n",
    "\n",
    "# Repeating the process for the tf matrix:\n",
    "tf_w2v_encoded = np.c_[ tf_w2v_product, rep_column ]\n",
    "\n",
    "tf_w2v_encoded = pd.DataFrame(tf_w2v_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.058452</td>\n",
       "      <td>0.368673</td>\n",
       "      <td>1.376803</td>\n",
       "      <td>-1.405207</td>\n",
       "      <td>-0.79821</td>\n",
       "      <td>0.603758</td>\n",
       "      <td>0.901007</td>\n",
       "      <td>-0.033724</td>\n",
       "      <td>1.251318</td>\n",
       "      <td>1.045505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123619</td>\n",
       "      <td>0.099695</td>\n",
       "      <td>0.266947</td>\n",
       "      <td>-0.754666</td>\n",
       "      <td>-0.445982</td>\n",
       "      <td>0.162899</td>\n",
       "      <td>-0.791294</td>\n",
       "      <td>0.261159</td>\n",
       "      <td>-1.3706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.822499</td>\n",
       "      <td>0.479263</td>\n",
       "      <td>1.476353</td>\n",
       "      <td>-1.188719</td>\n",
       "      <td>-0.748568</td>\n",
       "      <td>0.445022</td>\n",
       "      <td>0.899538</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>1.115131</td>\n",
       "      <td>0.828692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>-0.488914</td>\n",
       "      <td>0.242612</td>\n",
       "      <td>-0.90916</td>\n",
       "      <td>-0.18543</td>\n",
       "      <td>0.313198</td>\n",
       "      <td>-0.485337</td>\n",
       "      <td>0.047452</td>\n",
       "      <td>-1.002884</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.598499</td>\n",
       "      <td>0.606412</td>\n",
       "      <td>1.276193</td>\n",
       "      <td>-0.908887</td>\n",
       "      <td>-0.666337</td>\n",
       "      <td>0.483357</td>\n",
       "      <td>0.78959</td>\n",
       "      <td>-0.223053</td>\n",
       "      <td>1.028562</td>\n",
       "      <td>0.482812</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171464</td>\n",
       "      <td>-0.255339</td>\n",
       "      <td>0.376435</td>\n",
       "      <td>-0.702043</td>\n",
       "      <td>-0.152599</td>\n",
       "      <td>0.046016</td>\n",
       "      <td>-0.341507</td>\n",
       "      <td>-0.067445</td>\n",
       "      <td>-1.158638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.225319</td>\n",
       "      <td>0.339557</td>\n",
       "      <td>0.772748</td>\n",
       "      <td>-0.930528</td>\n",
       "      <td>-0.498734</td>\n",
       "      <td>-0.022198</td>\n",
       "      <td>0.520734</td>\n",
       "      <td>-0.158833</td>\n",
       "      <td>0.830174</td>\n",
       "      <td>0.537449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084208</td>\n",
       "      <td>-0.372784</td>\n",
       "      <td>0.174391</td>\n",
       "      <td>-0.667464</td>\n",
       "      <td>0.09056</td>\n",
       "      <td>-0.13596</td>\n",
       "      <td>-0.228646</td>\n",
       "      <td>0.039193</td>\n",
       "      <td>-0.856355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.598499</td>\n",
       "      <td>0.606412</td>\n",
       "      <td>1.276193</td>\n",
       "      <td>-0.908887</td>\n",
       "      <td>-0.666337</td>\n",
       "      <td>0.483357</td>\n",
       "      <td>0.78959</td>\n",
       "      <td>-0.223053</td>\n",
       "      <td>1.028562</td>\n",
       "      <td>0.482812</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171464</td>\n",
       "      <td>-0.255339</td>\n",
       "      <td>0.376435</td>\n",
       "      <td>-0.702043</td>\n",
       "      <td>-0.152599</td>\n",
       "      <td>0.046016</td>\n",
       "      <td>-0.341507</td>\n",
       "      <td>-0.067445</td>\n",
       "      <td>-1.158638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \n",
       "0 -2.058452  0.368673  1.376803 -1.405207  -0.79821  0.603758  0.901007  \\\n",
       "1 -1.822499  0.479263  1.476353 -1.188719 -0.748568  0.445022  0.899538   \n",
       "2 -1.598499  0.606412  1.276193 -0.908887 -0.666337  0.483357   0.78959   \n",
       "3 -1.225319  0.339557  0.772748 -0.930528 -0.498734 -0.022198  0.520734   \n",
       "4 -1.598499  0.606412  1.276193 -0.908887 -0.666337  0.483357   0.78959   \n",
       "\n",
       "        7         8         9    ...       191       192       193       194   \n",
       "0 -0.033724  1.251318  1.045505  ... -0.123619  0.099695  0.266947 -0.754666  \\\n",
       "1    -0.196  1.115131  0.828692  ...  0.005808 -0.488914  0.242612  -0.90916   \n",
       "2 -0.223053  1.028562  0.482812  ... -0.171464 -0.255339  0.376435 -0.702043   \n",
       "3 -0.158833  0.830174  0.537449  ...  0.084208 -0.372784  0.174391 -0.667464   \n",
       "4 -0.223053  1.028562  0.482812  ... -0.171464 -0.255339  0.376435 -0.702043   \n",
       "\n",
       "        195       196       197       198       199 200  \n",
       "0 -0.445982  0.162899 -0.791294  0.261159   -1.3706   1  \n",
       "1  -0.18543  0.313198 -0.485337  0.047452 -1.002884   0  \n",
       "2 -0.152599  0.046016 -0.341507 -0.067445 -1.158638   0  \n",
       "3   0.09056  -0.13596 -0.228646  0.039193 -0.856355   1  \n",
       "4 -0.152599  0.046016 -0.341507 -0.067445 -1.158638   0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_w2v_encoded.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final matrices:\n",
    "\n",
    "- tf_w2v_encoded\n",
    "\n",
    "- tf_idf_w2v_encoded "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===== Machine learning time ===="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the dataset into test and training set (and possibly a validation set, though I'm not completely sure how that works?)\n",
    "\n",
    "2. Train a random-forest classifier (?) on the train set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
