{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98413.49s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/christianstenbro/Programming/ripley_project/venv/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/christianstenbro/Programming/ripley_project/venv/lib/python3.10/site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/christianstenbro/Programming/ripley_project/venv/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/christianstenbro/Programming/ripley_project/venv/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/christianstenbro/Programming/ripley_project/venv/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method IndexOpsMixin.tolist of 0     In previous studies in English examining the i...\n",
      "1     Infants acquire whatever language is spoken in...\n",
      "2     Speech segmentation procedures may differ in s...\n",
      "3     Sentences with a contrastive intonation contou...\n",
      "4     Speech segmentation procedures may differ in s...\n",
      "                            ...                        \n",
      "92    Finnish vowel harmony rules require that if th...\n",
      "93    On a recognition test, if presentation of a me...\n",
      "94    In this study, we investigated automatic trans...\n",
      "95    This article addresses the questions of how an...\n",
      "96    The influence of phonology on visual word perc...\n",
      "Name: abstract, Length: 97, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "# Loading data from csv file (notice \"\" around the path)\n",
    "data = pd.read_csv(\"/Users/christianstenbro/Programming/ripley_project/Data_files/original_paper_data_frame_cleaned_v1.csv\")\n",
    "data.shape\n",
    "\n",
    "docs = data['abstract'].tolist # Indexing the abstract column from data frame, converting to list of strings\n",
    "\n",
    "print(docs) # Think about whether we should streamline the text (remove special characters etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 259)\t0.03307117897558947\n",
      "  (0, 196)\t0.05892198339166672\n",
      "  (0, 327)\t0.05892198339166672\n",
      "  (0, 63)\t0.05892198339166672\n",
      "  (0, 353)\t0.05892198339166672\n",
      "  (0, 164)\t0.05892198339166672\n",
      "  (0, 167)\t0.05892198339166672\n",
      "  (0, 58)\t0.05892198339166672\n",
      "  (0, 138)\t0.05892198339166672\n",
      "  (0, 324)\t0.05892198339166672\n",
      "  (0, 185)\t0.11784396678333343\n",
      "  (0, 212)\t0.037361281092715054\n",
      "  (0, 53)\t0.037361281092715054\n",
      "  (0, 336)\t0.04938122063544904\n",
      "  (0, 274)\t0.05892198339166672\n",
      "  (0, 161)\t0.05892198339166672\n",
      "  (0, 333)\t0.05892198339166672\n",
      "  (0, 245)\t0.029443949318754964\n",
      "  (0, 346)\t0.05892198339166672\n",
      "  (0, 108)\t0.05892198339166672\n",
      "  (0, 70)\t0.11784396678333343\n",
      "  (0, 407)\t0.05892198339166672\n",
      "  (0, 68)\t0.05892198339166672\n",
      "  (0, 153)\t0.037361281092715054\n",
      "  (0, 15)\t0.05892198339166672\n",
      "  :\t:\n",
      "  (7, 449)\t0.07682668369251033\n",
      "  (7, 53)\t0.03637688173357944\n",
      "  (7, 245)\t0.028668156733702106\n",
      "  (7, 153)\t0.03637688173357944\n",
      "  (7, 379)\t0.04808011851782522\n",
      "  (7, 406)\t0.07275376346715888\n",
      "  (7, 21)\t0.14334078366851055\n",
      "  (7, 409)\t0.1792622619491908\n",
      "  (7, 122)\t0.08297839471668297\n",
      "  (7, 151)\t0.06439963144730768\n",
      "  (7, 255)\t0.13746260453379713\n",
      "  (7, 399)\t0.12804447282085057\n",
      "  (7, 448)\t0.14550752693431776\n",
      "  (7, 431)\t0.07275376346715888\n",
      "  (7, 178)\t0.06873130226689857\n",
      "  (7, 446)\t0.028668156733702106\n",
      "  (7, 436)\t0.09659944717096151\n",
      "  (7, 417)\t0.06439963144730768\n",
      "  (7, 264)\t0.028668156733702106\n",
      "  (7, 54)\t0.028668156733702106\n",
      "  (7, 124)\t0.04808011851782522\n",
      "  (7, 41)\t0.03219981572365384\n",
      "  (7, 126)\t0.19319889434192303\n",
      "  (7, 191)\t0.04808011851782522\n",
      "  (7, 400)\t0.25201477497862806\n",
      "(8, 453)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = ['The experiment investigated locally ambiguous English sentences containing ?complement? verbs such as believe, which can be followed either by a direct object or by a complement clause. These two sentence types were compared with unambiguous sentences in which the complement clause was introduced by the word that. Subjects processed numerous examples of these sentences in a word-by-word self-paced reading task. At the disambiguation point after the ambiguous noun phrase, longer reading times were obtained for reduced complement constructions compared with direct object sentences. Such an effect has been attributed to the operation of the parsing principle Minimal Attachment (Frazier and Rayner, 1982). This principle predicts that subjects assume falsely that the noun phrase after the complement verb in the reduced complement constructions is the direct object, resulting in the need for subsequent structural reanalysis. However, longer times in the disambiguating zone were also found for the unambiguous that complements. Thus, the complexity difference seems not to represent ?garden-pathing? as a result of the operation of Minimal Attachment, but may instead reflect the extra complexity caused by having to handle two sets of clausal relations instead of just one.',\n",
    "          'In previous studies in English examining the influence of phonological neighbourhood density in spoken word production, words with many similar sounding words, or a dense neighbourhood, were produced more quickly and accurately than words with few similar sounding words, or a sparse neighbourhood. The influence of phonological neighbourhood density on the process of spoken word production in Spanish was examined with a picture-naming task. The results showed that pictures with Spanish names from sparse neighbourhoods were named more quickly than pictures with Spanish names from dense neighbourhoods. The present pattern of results is the opposite of what has been previously found in speech production in English. We hypothesise that differences in the morphology of Spanish and English and/or the location in the word where phonological neighbours tend to occur may contribute to the processing differences observed in the two languages.',\n",
    "          'The influence of phonology on visual word perception tasks is often indexed by the presence or absence ofconsistency effects.Consistency concerns whether there exists more than one way to pronounce a spelling body (e.g., _INT as in HINT and PINT versus _EAP as in HEAP and LEAP). The present study considers a similar factor.Feedbackconsistency concerns whether there is more than one way to spell a pronunciation body (e.g., /_ip/ as in HEAP and DEEP versus /_Ob/ as in PROBE and GLOBE). Two experiments demonstrate a robust feedback consistency effect in visual lexical decision. Words with phonologic bodies that can be spelled more than one way (e.g., _EAP as in HEAP) produce slower correct “yes” responses than words with phonologic bodies that can be spelled only one way (e.g., _OBE as in PROBE). This result constitutes strong support for feedback, top-down models of performance in word perception tasks. Furthermore, the data suggest that previous tests of consistency effects may be misleading because they did not take into account feedback consistency.',\n",
    "          'Infants acquire whatever language is spoken in the environment into which they are born. The mental capability of the newborn child is not biased in any way towards the acquisition of one human language rather than another. Because psychologists who attempt to model the process of language comprehension are interested in the structure of the human mind, rather than in the properties of individual languages, strategies which they incorporate in their models are presumed to be universal, not language-specific. In other words, strategies of comprehension are presumed to be characteristic of the human language processing system, rather than, say, the French, English, or Igbo language processing systems. We report here, however, on a comprehension strategy which appears to be used by native speakers of French but not by native speakers of English.',\n",
    "          'Speech segmentation procedures may differ in speakers of different languages. Earlier work based on French speakers listening to French words suggested that the syllable functions as a segmentation unit in speech processing. However, while French has relatively regular and clearly bounded syllables, other languages, such as English, do not. No trace of syllabifying segmentation was found in English listeners listening to English words, French words, or nonsense words. French listeners, however, showed evidence of syllabification even when they were listening to English words. We conclude that alternative segmentation routines are available to the human language processor. In some cases speech segmentation may involve the operation of more than one procedure.',\n",
    "          'Sentences with a contrastive intonation contour are usually produced when the speaker entertains alternatives to the accented words. However, such contrastive sentences are frequently produced without making the alternatives explicit for the listener. In two cross-modal associative priming experiments we tested in Dutch whether such contextual alternatives become available to listeners upon hearing a sentence with a contrastive intonation contour compared with a sentence with a non-contrastive one. The first experiment tested the recognition of contrastive associates (contextual alternatives to the sentence-final primes), the second one the recognition of non-contrastive associates (generic associates which are not alternatives). Results showed that contrastive associates were facilitated when the primes occurred in sentences with a contrastive intonation contour but not in sentences with a non-contrastive intonation. Non-contrastive associates were weakly facilitated independent of intonation. Possibly, contrastive contours trigger an accommodation mechanism by which listeners retrieve the contrast available for the speaker.',\n",
    "          'Recent theories of morphological processing have been dominated by the notion that morphologically complex words are decomposed into their constituents on the basis of their semantic properties. In this article we argue that the weight of evidence now suggests that the recognition of morphologically complex words begins with a rapid morphemic segmentation based solely on the analysis of orthography. Following a review of this evidence, we discuss the characteristics of this form of decomposition, speculate on what its purpose might be, consider how it might be learned in the developing reader, and describe what is known of its neural bases. Our discussion ends by reflecting on how evidence for semantically based decomposition might be (re)interpreted in the context of the orthographically based form of decomposition that we have described.',\n",
    "          'In this study, we investigated automatic translation from English to Chinese and subsequent morphological decomposition of translated Chinese compounds. In two lexical decision tasks, Chinese-English bilinguals responded to English target words that were preceded by masked unrelated primes presented for 59 ms. Unbeknownst to participants, the Chinese translations of the words in each critical pair consisted of a fully opaque compound word (i.e., a compound with two constituent morphemes that were semantically unrelated to the compound) and a monomorphemic word that was either the first or the second morpheme of the compound. The data revealed that bilinguals responded faster to English word pairs whose Chinese translations repeated the first morpheme than to English word pairs whose Chinese translations did not repeat the first morpheme, but no effect of hidden second-morpheme repetition was found. This effect of hidden first-morpheme repetition suggests that participants translated English words to Chinese and decomposed the translated compounds into their constituent morphemes. Because the primes were presented for only 59 ms, translation and morphological decomposition must be fast and automatic.',\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1982', '59', '_eap', '_int', '_ip', '_ob', '_obe', 'absence',\n",
       "       'accented', 'accommodation', 'account', 'accurately', 'acquire',\n",
       "       'acquisition', 'after', 'also', 'alternative', 'alternatives',\n",
       "       'ambiguous', 'an', 'analysis', 'and', 'another', 'any', 'appears',\n",
       "       'are', 'argue', 'article', 'as', 'associates', 'associative',\n",
       "       'assume', 'at', 'attachment', 'attempt', 'attributed', 'automatic',\n",
       "       'available', 'based', 'bases', 'basis', 'be', 'because', 'become',\n",
       "       'been', 'begins', 'believe', 'biased', 'bilinguals', 'bodies',\n",
       "       'body', 'born', 'bounded', 'but', 'by', 'can', 'capability',\n",
       "       'cases', 'caused', 'characteristic', 'characteristics', 'child',\n",
       "       'chinese', 'clausal', 'clause', 'clearly', 'compared',\n",
       "       'complement', 'complements', 'complex', 'complexity', 'compound',\n",
       "       'compounds', 'comprehension', 'concerns', 'conclude', 'consider',\n",
       "       'considers', 'consisted', 'consistency', 'constituent',\n",
       "       'constituents', 'constitutes', 'constructions', 'containing',\n",
       "       'context', 'contextual', 'contour', 'contours', 'contrast',\n",
       "       'contrastive', 'contribute', 'correct', 'critical', 'cross',\n",
       "       'data', 'decision', 'decomposed', 'decomposition', 'deep',\n",
       "       'demonstrate', 'dense', 'density', 'describe', 'described',\n",
       "       'developing', 'did', 'differ', 'difference', 'differences',\n",
       "       'different', 'direct', 'disambiguating', 'disambiguation',\n",
       "       'discuss', 'discussion', 'do', 'dominated', 'down', 'dutch',\n",
       "       'each', 'earlier', 'effect', 'effects', 'either', 'ends',\n",
       "       'english', 'entertains', 'environment', 'even', 'evidence',\n",
       "       'examined', 'examining', 'examples', 'exists', 'experiment',\n",
       "       'experiments', 'explicit', 'extra', 'facilitated', 'factor',\n",
       "       'falsely', 'fast', 'faster', 'feedback', 'feedbackconsistency',\n",
       "       'few', 'final', 'first', 'followed', 'following', 'for', 'form',\n",
       "       'found', 'frazier', 'french', 'frequently', 'from', 'fully',\n",
       "       'functions', 'furthermore', 'garden', 'generic', 'globe', 'handle',\n",
       "       'has', 'have', 'having', 'heap', 'hearing', 'here', 'hidden',\n",
       "       'hint', 'how', 'however', 'human', 'hypothesise', 'igbo', 'in',\n",
       "       'incorporate', 'independent', 'indexed', 'individual', 'infants',\n",
       "       'influence', 'instead', 'interested', 'interpreted', 'into',\n",
       "       'intonation', 'introduced', 'investigated', 'involve', 'is', 'it',\n",
       "       'its', 'just', 'known', 'language', 'languages', 'leap', 'learned',\n",
       "       'lexical', 'listener', 'listeners', 'listening', 'locally',\n",
       "       'location', 'longer', 'making', 'many', 'masked', 'may',\n",
       "       'mechanism', 'mental', 'might', 'mind', 'minimal', 'misleading',\n",
       "       'modal', 'model', 'models', 'monomorphemic', 'more', 'morpheme',\n",
       "       'morphemes', 'morphemic', 'morphological', 'morphologically',\n",
       "       'morphology', 'ms', 'must', 'named', 'names', 'naming', 'native',\n",
       "       'need', 'neighbourhood', 'neighbourhoods', 'neighbours', 'neural',\n",
       "       'newborn', 'no', 'non', 'nonsense', 'not', 'notion', 'noun', 'now',\n",
       "       'numerous', 'object', 'observed', 'obtained', 'occur', 'occurred',\n",
       "       'of', 'ofconsistency', 'often', 'on', 'one', 'only', 'opaque',\n",
       "       'operation', 'opposite', 'or', 'orthographically', 'orthography',\n",
       "       'other', 'our', 'paced', 'pair', 'pairs', 'parsing',\n",
       "       'participants', 'pathing', 'pattern', 'perception', 'performance',\n",
       "       'phonologic', 'phonological', 'phonology', 'phrase', 'picture',\n",
       "       'pictures', 'pint', 'point', 'possibly', 'preceded', 'predicts',\n",
       "       'presence', 'present', 'presented', 'presumed', 'previous',\n",
       "       'previously', 'primes', 'priming', 'principle', 'probe',\n",
       "       'procedure', 'procedures', 'process', 'processed', 'processing',\n",
       "       'processor', 'produce', 'produced', 'production', 'pronounce',\n",
       "       'pronunciation', 'properties', 'psychologists', 'purpose',\n",
       "       'quickly', 'rapid', 'rather', 'rayner', 're', 'reader', 'reading',\n",
       "       'reanalysis', 'recent', 'recognition', 'reduced', 'reflect',\n",
       "       'reflecting', 'regular', 'relations', 'relatively', 'repeat',\n",
       "       'repeated', 'repetition', 'report', 'represent', 'responded',\n",
       "       'responses', 'result', 'resulting', 'results', 'retrieve',\n",
       "       'revealed', 'review', 'robust', 'routines', 'say', 'second',\n",
       "       'seems', 'segmentation', 'self', 'semantic', 'semantically',\n",
       "       'sentence', 'sentences', 'sets', 'showed', 'similar', 'slower',\n",
       "       'solely', 'some', 'sounding', 'spanish', 'sparse', 'speaker',\n",
       "       'speakers', 'specific', 'speculate', 'speech', 'spell', 'spelled',\n",
       "       'spelling', 'spoken', 'strategies', 'strategy', 'strong',\n",
       "       'structural', 'structure', 'studies', 'study', 'subjects',\n",
       "       'subsequent', 'such', 'suggest', 'suggested', 'suggests',\n",
       "       'support', 'syllabification', 'syllabifying', 'syllable',\n",
       "       'syllables', 'system', 'systems', 'take', 'target', 'task',\n",
       "       'tasks', 'tend', 'tested', 'tests', 'than', 'that', 'the', 'their',\n",
       "       'theories', 'there', 'these', 'they', 'this', 'thus', 'times',\n",
       "       'to', 'top', 'towards', 'trace', 'translated', 'translation',\n",
       "       'translations', 'trigger', 'two', 'types', 'unambiguous',\n",
       "       'unbeknownst', 'unit', 'universal', 'unrelated', 'upon', 'used',\n",
       "       'usually', 'verb', 'verbs', 'versus', 'visual', 'was', 'way', 'we',\n",
       "       'weakly', 'weight', 'were', 'what', 'whatever', 'when', 'where',\n",
       "       'whether', 'which', 'while', 'who', 'whose', 'with', 'without',\n",
       "       'word', 'words', 'work', 'yes', 'zone'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the vocabulary\n",
    "#vectorizer.vocabulary_\n",
    "\n",
    "#vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the matrix as sparse vector (not needed for now):\n",
    "type(X)\n",
    "from scipy import sparse\n",
    "sparse.save_npz(\"tf_idf_vector.npz\", X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
