{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>bib</th>\n",
       "      <th>abstract</th>\n",
       "      <th>rep_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original_paper_ID</td>\n",
       "      <td>original_paper_bib</td>\n",
       "      <td>abstract</td>\n",
       "      <td>replication_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O1</td>\n",
       "      <td>Vitevitch, M. S. and Stamer, M. K. 2006. The c...</td>\n",
       "      <td>In previous studies in English examining the i...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O2</td>\n",
       "      <td>Cutler, A. , Mehler, J. , Noh, D. , and Seguí,...</td>\n",
       "      <td>Infants acquire whatever language is spoken in...</td>\n",
       "      <td>partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O2</td>\n",
       "      <td>Seguí, J. , 1986. The syllable's differing rol...</td>\n",
       "      <td>Speech segmentation procedures may differ in s...</td>\n",
       "      <td>partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O3</td>\n",
       "      <td>Braun , B. , &amp; Tagliapietra , L. 2009 The role...</td>\n",
       "      <td>Sentences with a contrastive intonation contou...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID                                                bib   \n",
       "0  original_paper_ID                                 original_paper_bib  \\\n",
       "1                 O1  Vitevitch, M. S. and Stamer, M. K. 2006. The c...   \n",
       "2                 O2  Cutler, A. , Mehler, J. , Noh, D. , and Seguí,...   \n",
       "3                 O2  Seguí, J. , 1986. The syllable's differing rol...   \n",
       "4                 O3  Braun , B. , & Tagliapietra , L. 2009 The role...   \n",
       "\n",
       "                                            abstract          rep_score  \n",
       "0                                           abstract  replication_score  \n",
       "1  In previous studies in English examining the i...                yes  \n",
       "2  Infants acquire whatever language is spoken in...            partial  \n",
       "3  Speech segmentation procedures may differ in s...            partial  \n",
       "4  Sentences with a contrastive intonation contou...                yes  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data and converting to panda dataframe (and changing/defining the names)\n",
    "\n",
    "data_file = '/Users/christianstenbro/Programming/ripley_project/Data_files/original_paper_data_frame_cleaned_v1.csv'\n",
    "\n",
    "data = pd.read_csv(data_file, sep=',', names=['ID', 'bib', 'abstract', 'rep_score'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 2595)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tfidf vectorizing the text and saving in a (sparse?) matrix\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "matrix = tfidf.fit_transform(data['abstract'].values.astype('U')) # the text needs to be converted to unicode strings (see https://stackoverflow.com/questions/39303912/tfidfvectorizer-in-scikit-learn-valueerror-np-nan-is-an-invalid-document)\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 79,\n",
       " 'in': 1151,\n",
       " 'previous': 1786,\n",
       " 'studies': 2251,\n",
       " 'english': 795,\n",
       " 'examining': 837,\n",
       " 'the': 2342,\n",
       " 'influence': 1187,\n",
       " 'of': 1585,\n",
       " 'phonological': 1704,\n",
       " 'neighbourhood': 1527,\n",
       " 'density': 643,\n",
       " 'spoken': 2195,\n",
       " 'word': 2566,\n",
       " 'production': 1817,\n",
       " 'words': 2567,\n",
       " 'with': 2562,\n",
       " 'many': 1397,\n",
       " 'similar': 2133,\n",
       " 'sounding': 2174,\n",
       " 'or': 1614,\n",
       " 'dense': 642,\n",
       " 'were': 2540,\n",
       " 'produced': 1815,\n",
       " 'more': 1479,\n",
       " 'quickly': 1865,\n",
       " 'and': 185,\n",
       " 'accurately': 97,\n",
       " 'than': 2340,\n",
       " 'few': 931,\n",
       " 'sparse': 2179,\n",
       " 'on': 1594,\n",
       " 'process': 1809,\n",
       " 'spanish': 2178,\n",
       " 'was': 2528,\n",
       " 'examined': 835,\n",
       " 'picture': 1715,\n",
       " 'naming': 1507,\n",
       " 'task': 2320,\n",
       " 'results': 2005,\n",
       " 'showed': 2119,\n",
       " 'that': 2341,\n",
       " 'pictures': 1716,\n",
       " 'names': 1506,\n",
       " 'from': 990,\n",
       " 'neighbourhoods': 1528,\n",
       " 'named': 1504,\n",
       " 'present': 1776,\n",
       " 'pattern': 1668,\n",
       " 'is': 1257,\n",
       " 'opposite': 1611,\n",
       " 'what': 2542,\n",
       " 'has': 1051,\n",
       " 'been': 309,\n",
       " 'previously': 1787,\n",
       " 'found': 975,\n",
       " 'speech': 2188,\n",
       " 'we': 2532,\n",
       " 'hypothesise': 1105,\n",
       " 'differences': 678,\n",
       " 'morphology': 1487,\n",
       " 'location': 1366,\n",
       " 'where': 2545,\n",
       " 'neighbours': 1529,\n",
       " 'tend': 2329,\n",
       " 'to': 2375,\n",
       " 'occur': 1581,\n",
       " 'may': 1413,\n",
       " 'contribute': 556,\n",
       " 'processing': 1812,\n",
       " 'observed': 1576,\n",
       " 'two': 2419,\n",
       " 'languages': 1293,\n",
       " 'psycinfo': 1851,\n",
       " 'database': 608,\n",
       " 'record': 1912,\n",
       " '2016': 33,\n",
       " 'apa': 197,\n",
       " 'all': 150,\n",
       " 'rights': 2029,\n",
       " 'reserved': 1989,\n",
       " 'infants': 1180,\n",
       " 'acquire': 101,\n",
       " 'whatever': 2543,\n",
       " 'language': 1292,\n",
       " 'environment': 805,\n",
       " 'into': 1236,\n",
       " 'which': 2551,\n",
       " 'they': 2357,\n",
       " 'are': 216,\n",
       " 'born': 348,\n",
       " 'mental': 1437,\n",
       " 'capability': 369,\n",
       " 'newborn': 1535,\n",
       " 'child': 403,\n",
       " 'not': 1557,\n",
       " 'biased': 329,\n",
       " 'any': 196,\n",
       " 'way': 2530,\n",
       " 'towards': 2386,\n",
       " 'acquisition': 103,\n",
       " 'one': 1595,\n",
       " 'human': 1095,\n",
       " 'rather': 1880,\n",
       " 'another': 190,\n",
       " 'because': 307,\n",
       " 'psychologists': 1849,\n",
       " 'who': 2554,\n",
       " 'attempt': 266,\n",
       " 'model': 1457,\n",
       " 'comprehension': 474,\n",
       " 'interested': 1217,\n",
       " 'structure': 2243,\n",
       " 'mind': 1449,\n",
       " 'properties': 1829,\n",
       " 'individual': 1174,\n",
       " 'strategies': 2230,\n",
       " 'incorporate': 1158,\n",
       " 'their': 2344,\n",
       " 'models': 1459,\n",
       " 'presumed': 1782,\n",
       " 'be': 304,\n",
       " 'universal': 2450,\n",
       " 'specific': 2184,\n",
       " 'other': 1626,\n",
       " 'characteristic': 395,\n",
       " 'system': 2307,\n",
       " 'say': 2053,\n",
       " 'french': 986,\n",
       " 'igbo': 1122,\n",
       " 'systems': 2310,\n",
       " 'report': 1972,\n",
       " 'here': 1068,\n",
       " 'however': 1092,\n",
       " 'strategy': 2231,\n",
       " 'appears': 204,\n",
       " 'used': 2467,\n",
       " 'by': 362,\n",
       " 'native': 1510,\n",
       " 'speakers': 2182,\n",
       " 'but': 361,\n",
       " 'segmentation': 2071,\n",
       " 'procedures': 1808,\n",
       " 'differ': 675,\n",
       " 'different': 679,\n",
       " 'earlier': 752,\n",
       " 'work': 2569,\n",
       " 'based': 298,\n",
       " 'listening': 1355,\n",
       " 'suggested': 2273,\n",
       " 'syllable': 2298,\n",
       " 'functions': 999,\n",
       " 'as': 234,\n",
       " 'unit': 2448,\n",
       " 'while': 2552,\n",
       " 'relatively': 1949,\n",
       " 'regular': 1937,\n",
       " 'clearly': 425,\n",
       " 'bounded': 354,\n",
       " 'syllables': 2299,\n",
       " 'such': 2268,\n",
       " 'do': 725,\n",
       " 'no': 1541,\n",
       " 'trace': 2388,\n",
       " 'syllabifying': 2297,\n",
       " 'listeners': 1354,\n",
       " 'nonsense': 1550,\n",
       " 'evidence': 827,\n",
       " 'syllabification': 2295,\n",
       " 'even': 823,\n",
       " 'when': 2544,\n",
       " 'conclude': 486,\n",
       " 'alternative': 162,\n",
       " 'routines': 2041,\n",
       " 'available': 284,\n",
       " 'processor': 1813,\n",
       " 'some': 2167,\n",
       " 'cases': 379,\n",
       " 'involve': 1252,\n",
       " 'operation': 1606,\n",
       " 'procedure': 1807,\n",
       " 'sentences': 2087,\n",
       " 'contrastive': 554,\n",
       " 'intonation': 1237,\n",
       " 'contour': 549,\n",
       " 'usually': 2473,\n",
       " 'speaker': 2181,\n",
       " 'entertains': 802,\n",
       " 'alternatives': 163,\n",
       " 'accented': 82,\n",
       " 'frequently': 989,\n",
       " 'without': 2564,\n",
       " 'making': 1389,\n",
       " 'explicit': 868,\n",
       " 'for': 963,\n",
       " 'listener': 1353,\n",
       " 'cross': 593,\n",
       " 'modal': 1456,\n",
       " 'associative': 256,\n",
       " 'priming': 1794,\n",
       " 'experiments': 865,\n",
       " 'tested': 2336,\n",
       " 'dutch': 746,\n",
       " 'whether': 2548,\n",
       " 'contextual': 545,\n",
       " 'become': 308,\n",
       " 'upon': 2464,\n",
       " 'hearing': 1059,\n",
       " 'sentence': 2086,\n",
       " 'compared': 451,\n",
       " 'non': 1544,\n",
       " 'first': 944,\n",
       " 'experiment': 862,\n",
       " 'recognition': 1907,\n",
       " 'associates': 253,\n",
       " 'final': 938,\n",
       " 'primes': 1793,\n",
       " 'second': 2064,\n",
       " 'generic': 1018,\n",
       " 'facilitated': 895,\n",
       " 'occurred': 1582,\n",
       " 'weakly': 2534,\n",
       " 'independent': 1167,\n",
       " 'possibly': 1744,\n",
       " 'contours': 550,\n",
       " 'trigger': 2410,\n",
       " 'an': 175,\n",
       " 'accommodation': 87,\n",
       " 'mechanism': 1427,\n",
       " 'retrieve': 2010,\n",
       " 'contrast': 552,\n",
       " 'recent': 1901,\n",
       " 'theories': 2350,\n",
       " 'morphological': 1485,\n",
       " 'have': 1052,\n",
       " 'dominated': 730,\n",
       " 'notion': 1561,\n",
       " 'morphologically': 1486,\n",
       " 'complex': 463,\n",
       " 'decomposed': 617,\n",
       " 'constituents': 525,\n",
       " 'basis': 302,\n",
       " 'semantic': 2078,\n",
       " 'this': 2359,\n",
       " 'article': 229,\n",
       " 'argue': 217,\n",
       " 'weight': 2536,\n",
       " 'now': 1565,\n",
       " 'suggests': 2275,\n",
       " 'begins': 313,\n",
       " 'rapid': 1875,\n",
       " 'morphemic': 1483,\n",
       " 'solely': 2164,\n",
       " 'analysis': 179,\n",
       " 'orthography': 1624,\n",
       " 'following': 961,\n",
       " 'review': 2021,\n",
       " 'discuss': 698,\n",
       " 'characteristics': 396,\n",
       " 'form': 967,\n",
       " 'decomposition': 618,\n",
       " 'speculate': 2187,\n",
       " 'its': 1262,\n",
       " 'purpose': 1856,\n",
       " 'might': 1447,\n",
       " 'consider': 511,\n",
       " 'how': 1091,\n",
       " 'it': 1259,\n",
       " 'learned': 1313,\n",
       " 'developing': 671,\n",
       " 'reader': 1886,\n",
       " 'describe': 652,\n",
       " 'known': 1281,\n",
       " 'neural': 1530,\n",
       " 'bases': 299,\n",
       " 'our': 1628,\n",
       " 'discussion': 701,\n",
       " 'ends': 794,\n",
       " 'reflecting': 1927,\n",
       " 'semantically': 2079,\n",
       " 're': 1882,\n",
       " 'interpreted': 1231,\n",
       " 'context': 543,\n",
       " 'orthographically': 1623,\n",
       " 'described': 653,\n",
       " 'gating': 1008,\n",
       " 'paradigm': 1647,\n",
       " 'grosjean': 1037,\n",
       " '1980': 14,\n",
       " 'determine': 666,\n",
       " 'whethersubjects': 2549,\n",
       " 'potentially': 1750,\n",
       " 'last': 1298,\n",
       " 'thiscase': 2360,\n",
       " 'noun': 1562,\n",
       " 'before': 310,\n",
       " 'optional': 1612,\n",
       " 'prepositional': 1773,\n",
       " 'phrase': 1710,\n",
       " 'can': 365,\n",
       " 'indicate': 1171,\n",
       " 'whetherthe': 2550,\n",
       " 'over': 1633,\n",
       " 'if': 1121,\n",
       " 'much': 1497,\n",
       " 'longer': 1372,\n",
       " 'will': 2559,\n",
       " 'contained': 538,\n",
       " 'endings': 793,\n",
       " 'ranging': 1874,\n",
       " 'length': 1322,\n",
       " 'zero': 2592,\n",
       " 'nine': 1538,\n",
       " 'wordswere': 2568,\n",
       " 'gated': 1007,\n",
       " 'object': 1571,\n",
       " 'presented': 1778,\n",
       " 'subjects': 2257,\n",
       " 'had': 1045,\n",
       " 'choosewhich': 411,\n",
       " 'four': 976,\n",
       " 'being': 315,\n",
       " 'press': 1781,\n",
       " 'key': 1273,\n",
       " 'at': 262,\n",
       " 'point': 1730,\n",
       " 'timewhen': 2373,\n",
       " 'felt': 926,\n",
       " 'would': 2575,\n",
       " 'ended': 791,\n",
       " 'full': 994,\n",
       " 'basing': 301,\n",
       " 'themselves': 2347,\n",
       " 'prosodic': 1836,\n",
       " 'cues': 596,\n",
       " 'subjectswere': 2258,\n",
       " 'surprisingly': 2291,\n",
       " 'accurate': 96,\n",
       " 'predicting': 1759,\n",
       " 'upcoming': 2463,\n",
       " 'acoustic': 100,\n",
       " 'test': 2335,\n",
       " 'strong': 2237,\n",
       " 'relationshipbetween': 1946,\n",
       " 'measures': 1425,\n",
       " 'fundamental': 1000,\n",
       " 'frequency': 987,\n",
       " 'amplitude': 174,\n",
       " 'duration': 744,\n",
       " 'andthe': 186,\n",
       " 'experimental': 863,\n",
       " 'data': 607,\n",
       " 'these': 2356,\n",
       " 'findings': 942,\n",
       " 'discussed': 699,\n",
       " 'terms': 2334,\n",
       " 'predictiveand': 1762,\n",
       " 'interpretative': 1230,\n",
       " 'roles': 2038,\n",
       " 'prosody': 1839,\n",
       " 'during': 745,\n",
       " 'line': 1346,\n",
       " 'lan': 1291,\n",
       " 'guage': 1042,\n",
       " 'concepts': 481,\n",
       " 'stereotypes': 2218,\n",
       " 'leaves': 1317,\n",
       " 'open': 1604,\n",
       " 'question': 1863,\n",
       " 'argued': 218,\n",
       " 'elsewhere': 773,\n",
       " 'identify': 1116,\n",
       " 'stereotypical': 2219,\n",
       " 'instances': 1201,\n",
       " 'rosch': 2039,\n",
       " '1978': 13,\n",
       " 'principles': 1796,\n",
       " 'categorization': 383,\n",
       " 'lloyd': 1361,\n",
       " 'ed': 759,\n",
       " 'cognition': 432,\n",
       " 'hillsdale': 1079,\n",
       " 'nj': 1540,\n",
       " 'lawrence': 1305,\n",
       " 'erlbaum': 812,\n",
       " 'smith': 2161,\n",
       " 'medin': 1430,\n",
       " '1981': 15,\n",
       " 'categories': 382,\n",
       " 'cambridge': 363,\n",
       " 'ma': 1381,\n",
       " 'harvard': 1050,\n",
       " 'university': 2451,\n",
       " 'fail': 905,\n",
       " 'provide': 1842,\n",
       " 'adequate': 121,\n",
       " 'account': 91,\n",
       " 'compositionality': 469,\n",
       " 'fodor': 957,\n",
       " 'lepore': 1324,\n",
       " '1996': 20,\n",
       " 'red': 1915,\n",
       " 'herring': 1069,\n",
       " 'pet': 1690,\n",
       " 'fish': 945,\n",
       " 'why': 2557,\n",
       " 'still': 2222,\n",
       " 'cannot': 366,\n",
       " 'prototypes': 1840,\n",
       " '58': 59,\n",
       " '253': 37,\n",
       " '270': 40,\n",
       " '1998': 22,\n",
       " 'cognitive': 433,\n",
       " 'science': 2058,\n",
       " 'went': 2539,\n",
       " 'wrong': 2577,\n",
       " 'new': 1534,\n",
       " 'york': 2587,\n",
       " 'ny': 1570,\n",
       " 'oxford': 1638,\n",
       " 'paper': 1646,\n",
       " 'extends': 883,\n",
       " 'argument': 220,\n",
       " 'reports': 1974,\n",
       " 'suggesting': 2274,\n",
       " 'participants': 1658,\n",
       " 'assume': 258,\n",
       " 'default': 623,\n",
       " 'inherit': 1191,\n",
       " 'thus': 2370,\n",
       " 'propositions': 1835,\n",
       " 'baby': 289,\n",
       " 'ducks': 742,\n",
       " 'webbed': 2535,\n",
       " 'feet': 925,\n",
       " 'judged': 1267,\n",
       " 'less': 1325,\n",
       " 'likely': 1343,\n",
       " 'true': 2414,\n",
       " 'like': 1340,\n",
       " 'moreover': 1480,\n",
       " 'manipulation': 1395,\n",
       " 'type': 2420,\n",
       " 'number': 1566,\n",
       " 'modifiers': 1462,\n",
       " 'revealed': 2014,\n",
       " 'systematic': 2308,\n",
       " 'departure': 644,\n",
       " 'unmodified': 2456,\n",
       " 'stereotype': 2217,\n",
       " 'both': 351,\n",
       " 'addition': 113,\n",
       " 'quacking': 1858,\n",
       " 'versus': 2503,\n",
       " 'modifier': 1461,\n",
       " 'peruvian': 1689,\n",
       " 'general': 1011,\n",
       " 'case': 378,\n",
       " 'head': 1054,\n",
       " 'systematically': 2309,\n",
       " 'discounted': 692,\n",
       " 'combines': 444,\n",
       " 'effect': 761,\n",
       " 'represents': 1980,\n",
       " 'principle': 1795,\n",
       " 'conceptual': 482,\n",
       " 'combination': 440,\n",
       " 'argues': 219,\n",
       " 'against': 142,\n",
       " 'inheritance': 1192,\n",
       " 'features': 921,\n",
       " 'instead': 1202,\n",
       " 'advocate': 134,\n",
       " 'remain': 1956,\n",
       " 'inert': 1179,\n",
       " 'under': 2435,\n",
       " 'supported': 2284,\n",
       " 'separate': 2088,\n",
       " 'machinery': 1382,\n",
       " 'introduces': 1239,\n",
       " 'pragmatic': 1754,\n",
       " 'knowledge': 1280,\n",
       " 'dependent': 648,\n",
       " 'inferences': 1182,\n",
       " 'investigated': 1246,\n",
       " 'ambiguous': 169,\n",
       " 'containing': 540,\n",
       " 'complement': 458,\n",
       " 'verbs': 2500,\n",
       " 'believe': 316,\n",
       " 'followed': 960,\n",
       " 'direct': 688,\n",
       " 'clause': 422,\n",
       " 'types': 2421,\n",
       " 'unambiguous': 2429,\n",
       " 'clauses': 423,\n",
       " 'introduced': 1238,\n",
       " '33': 50,\n",
       " 'undergraduates': 2438,\n",
       " 'processed': 1810,\n",
       " 'numerous': 1568,\n",
       " 'reading': 1889,\n",
       " 'disambiguation': 691,\n",
       " 'after': 140,\n",
       " 'times': 2372,\n",
       " 'obtained': 1578,\n",
       " 'reduced': 1917,\n",
       " 'constructions': 534,\n",
       " 'complements': 460,\n",
       " 'concluded': 487,\n",
       " 'complexity': 464,\n",
       " 'difference': 677,\n",
       " 'does': 727,\n",
       " 'represent': 1976,\n",
       " 'garden': 1006,\n",
       " 'pathing': 1666,\n",
       " 'reanalysis': 1893,\n",
       " 'result': 2003,\n",
       " 'minimal': 1450,\n",
       " 'attachment': 264,\n",
       " 'proposed': 1834,\n",
       " 'frazier': 984,\n",
       " 'rayner': 1881,\n",
       " 'see': 2067,\n",
       " '1982': 16,\n",
       " '20309': 34,\n",
       " '001': 0,\n",
       " 'reflect': 1925,\n",
       " 'extra': 885,\n",
       " 'caused': 386,\n",
       " 'having': 1053,\n",
       " 'handle': 1048,\n",
       " 'sets': 2096,\n",
       " 'clausal': 421,\n",
       " 'relations': 1944,\n",
       " 'just': 1270,\n",
       " 'interference': 1221,\n",
       " 'reported': 1973,\n",
       " 'boundaries': 352,\n",
       " 'explored': 873,\n",
       " 'car': 373,\n",
       " 'appeared': 203,\n",
       " 'superimposed': 2281,\n",
       " 'distractors': 721,\n",
       " 'distractor': 720,\n",
       " 'same': 2051,\n",
       " 'category': 384,\n",
       " 'whereas': 2546,\n",
       " 'related': 1940,\n",
       " 'bumper': 360,\n",
       " 'led': 1319,\n",
       " 'facilitation': 896,\n",
       " 'replicated': 1970,\n",
       " 'relationship': 1945,\n",
       " 'between': 325,\n",
       " 'necessarily': 1517,\n",
       " 'lead': 1308,\n",
       " 'fact': 898,\n",
       " 'until': 2461,\n",
       " 'implications': 1142,\n",
       " 'assumption': 260,\n",
       " 'arises': 222,\n",
       " 'consequence': 509,\n",
       " 'lexical': 1331,\n",
       " 'competition': 456,\n",
       " 'stroop': 2240,\n",
       " 'color': 438,\n",
       " 'administered': 125,\n",
       " 'children': 405,\n",
       " 'unable': 2427,\n",
       " 'read': 1885,\n",
       " 'hundred': 1096,\n",
       " 'sixty': 2147,\n",
       " 'eight': 765,\n",
       " '3½': 53,\n",
       " '6½': 62,\n",
       " 'years': 2583,\n",
       " '50': 58,\n",
       " 'female': 927,\n",
       " '24': 36,\n",
       " 'each': 751,\n",
       " 'month': 1478,\n",
       " 'interval': 1234,\n",
       " 'shown': 2121,\n",
       " 'drawings': 738,\n",
       " 'familiar': 909,\n",
       " 'objects': 1572,\n",
       " 'congruent': 504,\n",
       " 'orange': 1615,\n",
       " 'carrot': 376,\n",
       " 'incongruent': 1156,\n",
       " 'green': 1035,\n",
       " 'neutral': 1533,\n",
       " 'canonical': 367,\n",
       " 'book': 345,\n",
       " 'shapes': 2107,\n",
       " 'drawn': 739,\n",
       " 'six': 2146,\n",
       " 'colors': 439,\n",
       " 'half': 1046,\n",
       " 'asked': 238,\n",
       " 'name': 1503,\n",
       " 'predominant': 1765,\n",
       " 'tendency': 2330,\n",
       " 'instructed': 1203,\n",
       " 'otherwise': 1627,\n",
       " 'slower': 2158,\n",
       " 'faster': 915,\n",
       " 'stimulus': 2224,\n",
       " 'could': 584,\n",
       " 'shape': 2106,\n",
       " 'heightened': 1065,\n",
       " 'due': 743,\n",
       " 'lack': 1287,\n",
       " 'familiarity': 910,\n",
       " 'group': 1039,\n",
       " 'condition': 492,\n",
       " 'fast': 914,\n",
       " 'most': 1488,\n",
       " 'productive': 1819,\n",
       " 'class': 416,\n",
       " 'exemplified': 845,\n",
       " 'verb': 2496,\n",
       " 'string': 2234,\n",
       " 'strung': 2247,\n",
       " 'historical': 1081,\n",
       " 'show': 2118,\n",
       " 'phono': 1702,\n",
       " 'logically': 1370,\n",
       " 'defined': 626,\n",
       " 'members': 1433,\n",
       " 'share': 2108,\n",
       " 'single': 2144,\n",
       " 'set': 2095,\n",
       " 'fea': 917,\n",
       " 'tures': 2416,\n",
       " 'organized': 1618,\n",
       " 'around': 224,\n",
       " 'prototypical': 1841,\n",
       " 'member': 1432,\n",
       " 'sense': 2081,\n",
       " 'stand': 2205,\n",
       " 'family': 911,\n",
       " 'resemblance': 1988,\n",
       " 'relation': 1943,\n",
       " 'wittgenstein': 2565,\n",
       " '1953': 10,\n",
       " 'defining': 627,\n",
       " 'attributes': 275,\n",
       " 'include': 1152,\n",
       " 'consonants': 522,\n",
       " 'well': 2538,\n",
       " 'initial': 1196,\n",
       " 'consonant': 520,\n",
       " 'clusters': 429,\n",
       " 'lesser': 1326,\n",
       " 'extent': 884,\n",
       " 'vowel': 2520,\n",
       " 'base': 297,\n",
       " 'organization': 1617,\n",
       " 'formal': 968,\n",
       " 'aspects': 239,\n",
       " 'linguistic': 1348,\n",
       " 'units': 2449,\n",
       " 'follow': 959,\n",
       " 'content': 542,\n",
       " 'classes': 417,\n",
       " 'natural': 1511,\n",
       " 'cultural': 597,\n",
       " 'examines': 836,\n",
       " 'talkers': 2317,\n",
       " 'utterances': 2477,\n",
       " 'time': 2371,\n",
       " 'monolog': 1475,\n",
       " 'old': 1591,\n",
       " 'finding': 941,\n",
       " 'distinguish': 717,\n",
       " 'shortening': 2115,\n",
       " 'them': 2345,\n",
       " 'intelligible': 1211,\n",
       " 'isolation': 1258,\n",
       " 'probably': 1802,\n",
       " 'identifiable': 1112,\n",
       " 'infer': 1181,\n",
       " 'attenuate': 271,\n",
       " 'productions': 1818,\n",
       " 'so': 2162,\n",
       " 'sacrificing': 2046,\n",
       " 'communicative': 449,\n",
       " 'efficacy': 763,\n",
       " 'repetitions': 1968,\n",
       " 'items': 1261,\n",
       " 'support': 2283,\n",
       " 'receive': 1897,\n",
       " 'use': 2466,\n",
       " 'information': 1190,\n",
       " 'anaphor': 182,\n",
       " 'promote': 1823,\n",
       " 'retrieval': 2008,\n",
       " 'series': 2092,\n",
       " 'three': 2365,\n",
       " 'exploring': 874,\n",
       " 'effects': 762,\n",
       " 'repeated': 1965,\n",
       " 'aloud': 158,\n",
       " 'auditorily': 278,\n",
       " 'then': 2348,\n",
       " 'targets': 2319,\n",
       " 'prime': 1791,\n",
       " 'target': 2318,\n",
       " 'shared': 2109,\n",
       " 'phonemes': 1698,\n",
       " 'only': 1599,\n",
       " 'occupied': 1580,\n",
       " 'syllabic': 2294,\n",
       " 'positions': 1740,\n",
       " 'degree': 630,\n",
       " 'unaffected': 2428,\n",
       " 'lexicality': 1332,\n",
       " 'early': 753,\n",
       " 'late': 1299,\n",
       " 'intervals': 1235,\n",
       " 'response': 2000,\n",
       " 'tease': 2325,\n",
       " 'apart': 198,\n",
       " 'contributions': 559,\n",
       " 'automatic': 281,\n",
       " 'strategic': 2229,\n",
       " 'processes': 1811,\n",
       " 'considered': 514,\n",
       " 'current': 600,\n",
       " 'accounts': 93,\n",
       " 'portuguese': 1737,\n",
       " 'materials': 1410,\n",
       " 'consistency': 517,\n",
       " 'ziegler': 2594,\n",
       " 'ferrand': 929,\n",
       " 'rimes': 2031,\n",
       " 'spelled': 2192,\n",
       " 'ways': 2531,\n",
       " 'inconsistent': 1157,\n",
       " 'auditory': 279,\n",
       " 'decision': 612,\n",
       " 'latencies': 1300,\n",
       " 'errors': 814,\n",
       " 'did': 674,\n",
       " 'consistent': 518,\n",
       " 'shadowing': 2104,\n",
       " 'orthographic': 1622,\n",
       " 'confinement': 496,\n",
       " 'influences': 1188,\n",
       " 'either': 766,\n",
       " 'decisional': 613,\n",
       " 'tried': 2409,\n",
       " 'untangle': 2460,\n",
       " 'interpretations': 1229,\n",
       " 'comparing': 452,\n",
       " 'situations': 2145,\n",
       " 'made': 1383,\n",
       " 'contingent': 546,\n",
       " 'phonemic': 1699,\n",
       " 'criterion': 591,\n",
       " 'significant': 2131,\n",
       " 'lexically': 1333,\n",
       " 'sublexical': 2260,\n",
       " 'affected': 136,\n",
       " 'course': 588,\n",
       " 'encoding': 787,\n",
       " 'methodology': 1445,\n",
       " 'required': 1983,\n",
       " 'monitor': 1470,\n",
       " 'internal': 1223,\n",
       " 'prespecified': 1780,\n",
       " 'segments': 2072,\n",
       " 'demonstrated': 640,\n",
       " 'monitored': 1471,\n",
       " 'significantly': 2132,\n",
       " 'concurrent': 491,\n",
       " 'articulation': 231,\n",
       " '1b': 24,\n",
       " 'limited': 1345,\n",
       " 'performance': 1681,\n",
       " 'excluding': 841,\n",
       " 'possibility': 1742,\n",
       " 'monitoring': 1472,\n",
       " 'subvocal': 2266,\n",
       " 'carrier': 374,\n",
       " 'timing': 2374,\n",
       " 'overt': 1636,\n",
       " 'therefore': 2355,\n",
       " 'phonetic': 1700,\n",
       " 'representation': 1977,\n",
       " 'replicate': 1969,\n",
       " 'perception': 1677,\n",
       " 'responses': 2001,\n",
       " 'corresponded': 575,\n",
       " 'generation': 1017,\n",
       " 'syllabified': 2296,\n",
       " 'provides': 1844,\n",
       " 'detailed': 662,\n",
       " 'concerning': 484,\n",
       " 'within': 2563,\n",
       " 'amendments': 170,\n",
       " 'light': 1338,\n",
       " 'observation': 1574,\n",
       " 'favor': 916,\n",
       " 'functional': 997,\n",
       " 'role': 2037,\n",
       " 'stored': 2226,\n",
       " 'accordingly': 90,\n",
       " 'various': 2488,\n",
       " 'theoretical': 2349,\n",
       " 'postulate': 1746,\n",
       " 'repository': 1975,\n",
       " 'representations': 1978,\n",
       " 'accessed': 84,\n",
       " 'empirical': 782,\n",
       " 'locating': 1365,\n",
       " 'level': 1329,\n",
       " 'motor': 1491,\n",
       " 'programming': 1822,\n",
       " 'levels': 1330,\n",
       " 'scarce': 2055,\n",
       " 'investigate': 1245,\n",
       " 'origin': 1619,\n",
       " 'conducted': 495,\n",
       " 'involving': 1254,\n",
       " 'immediate': 1131,\n",
       " 'delayed': 634,\n",
       " 'interfering': 1222,\n",
       " 'articulatory': 232,\n",
       " 'suppression': 2288,\n",
       " 'psycholinguistic': 1847,\n",
       " 'short': 2114,\n",
       " 'term': 2333,\n",
       " 'memory': 1436,\n",
       " 'allows': 156,\n",
       " 'working': 2571,\n",
       " 'hypothesis': 1104,\n",
       " 'disrupts': 708,\n",
       " 'leaving': 1318,\n",
       " 'intact': 1207,\n",
       " 'pseudo': 1845,\n",
       " 'respectively': 1995,\n",
       " 'delay': 633,\n",
       " 'presentation': 1777,\n",
       " 'cue': 594,\n",
       " 'filled': 935,\n",
       " 'standard': 2206,\n",
       " 'highly': 1077,\n",
       " 'affects': 137,\n",
       " 'stage': 2203,\n",
       " 'interpretation': 1228,\n",
       " 'postulated': 1747,\n",
       " 'involves': 1253,\n",
       " 'sized': 2148,\n",
       " 'visual': 2513,\n",
       " 'world': 2572,\n",
       " 'eye': 888,\n",
       " 'tracking': 2390,\n",
       " 'prediction': 1760,\n",
       " 'repair': 1962,\n",
       " 'disfluencies': 702,\n",
       " 'chef': 401,\n",
       " 'reached': 1883,\n",
       " 'salt': 2050,\n",
       " 'uh': 2425,\n",
       " 'mean': 1416,\n",
       " 'ketchup': 1272,\n",
       " 'fixate': 947,\n",
       " 'critical': 592,\n",
       " 'item': 1260,\n",
       " 'pepper': 1674,\n",
       " 'coordination': 569,\n",
       " 'structures': 2245,\n",
       " 'also': 160,\n",
       " 'disfluency': 703,\n",
       " 'fixations': 949,\n",
       " 'fixation': 948,\n",
       " 'patterns': 1669,\n",
       " 'employing': 784,\n",
       " 'focus': 956,\n",
       " 'suggest': 2272,\n",
       " 'mechanisms': 1428,\n",
       " 'underlie': 2439,\n",
       " 'generating': 1016,\n",
       " 'entities': 803,\n",
       " 'reparandum': 1963,\n",
       " 'negated': 1520,\n",
       " 'entity': 804,\n",
       " 'vowels': 2521,\n",
       " 'importance': 1147,\n",
       " 'recently': 1902,\n",
       " 'play': 1723,\n",
       " 'important': 1148,\n",
       " 'adult': 127,\n",
       " 'proposal': 1832,\n",
       " 'started': 2208,\n",
       " 'receiving': 1900,\n",
       " 'developmental': 673,\n",
       " 'showing': 2120,\n",
       " 'better': 324,\n",
       " 'consonantal': 521,\n",
       " 'vocalic': 2518,\n",
       " 'learning': 1315,\n",
       " 'received': 1898,\n",
       " 'study': 2252,\n",
       " 'directly': 690,\n",
       " 'relative': 1948,\n",
       " 'access': 83,\n",
       " 'using': 2471,\n",
       " 'masked': 1404,\n",
       " 'identity': 1117,\n",
       " 'joli': 1266,\n",
       " 'unrelated': 2459,\n",
       " 'vabu': 2478,\n",
       " 'jalu': 1264,\n",
       " 'vobi': 2515,\n",
       " 'conditions': 494,\n",
       " 'establish': 818,\n",
       " 'privileged': 1799,\n",
       " 'eyetracking': 889,\n",
       " 'plurality': 1727,\n",
       " 'parsing': 1656,\n",
       " 'decisions': 614,\n",
       " 'temporarily': 2328,\n",
       " 'reciprocal': 1904,\n",
       " 'lovers': 1376,\n",
       " 'kissed': 1276,\n",
       " 'played': 1724,\n",
       " 'alone': 157,\n",
       " 'varied': 2486,\n",
       " 'subject': 2256,\n",
       " 'plural': 1726,\n",
       " 'phrases': 1711,\n",
       " 'conjoined': 506,\n",
       " 'bride': 357,\n",
       " 'groom': 1036,\n",
       " 'definite': 628,\n",
       " 'descriptions': 656,\n",
       " 'numerically': 1567,\n",
       " 'quantified': 1861,\n",
       " 'path': 1665,\n",
       " 'ferreira': 930,\n",
       " 'mcclure': 1414,\n",
       " '1997': 21,\n",
       " 'traditional': 2395,\n",
       " 'anaphors': 183,\n",
       " 'antecedent': 194,\n",
       " 'discourse': 693,\n",
       " 'absent': 77,\n",
       " 'description': 655,\n",
       " 'parser': 1655,\n",
       " 'sensitive': 2084,\n",
       " 'constituent': 524,\n",
       " 'particular': 1662,\n",
       " 'reference': 1920,\n",
       " 'moxey': 1495,\n",
       " 'et': 819,\n",
       " 'al': 149,\n",
       " '2004': 29,\n",
       " 'automatically': 282,\n",
       " 'activates': 108,\n",
       " 'lexicon': 1334,\n",
       " 'answers': 193,\n",
       " 'ranged': 1873,\n",
       " 'listing': 1356,\n",
       " 'every': 825,\n",
       " 'storage': 2225,\n",
       " 'domain': 729,\n",
       " 'suffix': 2270,\n",
       " 'en': 785,\n",
       " 'occurs': 1583,\n",
       " 'high': 1073,\n",
       " 'plurals': 1728,\n",
       " 'mathematical': 1411,\n",
       " 'formalization': 969,\n",
       " 'parallel': 1651,\n",
       " 'dual': 741,\n",
       " 'route': 2040,\n",
       " 'race': 1866,\n",
       " 'reaction': 1884,\n",
       " 'essentially': 817,\n",
       " 'free': 985,\n",
       " 'parameter': 1652,\n",
       " 'speed': 2189,\n",
       " 'costly': 582,\n",
       " 'attribute': 273,\n",
       " 'ambiguity': 168,\n",
       " 'predominantly': 1766,\n",
       " 'verbal': 2497,\n",
       " 'ending': 792,\n",
       " 'third': 2358,\n",
       " 'contrasted': 553,\n",
       " 'nouns': 1563,\n",
       " 'surface': 2289,\n",
       " 'again': 141,\n",
       " 'solid': 2165,\n",
       " 'together': 2376,\n",
       " ...}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the vocabulary\n",
    "tfidf.vocabulary_ # is the number the overall corpus frequency associated with each word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract: \"O4\"\n",
      "TF-IDF score: 0.103853\n",
      "  (0, 79)\t1.0\n",
      "  (1, 1989)\t0.07840805166052696\n",
      "  (1, 2029)\t0.07840805166052696\n",
      "  (1, 150)\t0.053784483766245235\n",
      "  (1, 197)\t0.07840805166052696\n",
      "  (1, 33)\t0.07840805166052696\n",
      "  (1, 1912)\t0.07085446474511206\n",
      "  (1, 608)\t0.07840805166052696\n",
      "  (1, 1851)\t0.07840805166052696\n",
      "  (1, 1293)\t0.05956249563789154\n",
      "  (1, 2419)\t0.036964566106560875\n",
      "  (1, 1576)\t0.057941522623005705\n",
      "  (1, 1812)\t0.04150310848436469\n",
      "  (1, 556)\t0.08376740686721841\n",
      "  (1, 1413)\t0.055069782157893064\n",
      "  (1, 1581)\t0.07425101280376649\n",
      "  (1, 2375)\t0.040810025213235276\n",
      "  (1, 2329)\t0.09132099378263332\n",
      "  (1, 1529)\t0.09132099378263332\n",
      "  (1, 2545)\t0.06330087782969718\n",
      "  (1, 1366)\t0.09132099378263332\n",
      "  (1, 1487)\t0.07840805166052696\n",
      "  (1, 678)\t0.1309902190768412\n",
      "  (1, 1105)\t0.09132099378263332\n",
      "  (1, 2532)\t0.034603253120371824\n",
      "  :\t:\n",
      "  (97, 1595)\t0.17374025638184107\n",
      "  (97, 2530)\t0.24392810360149558\n",
      "  (97, 1557)\t0.02990264013947055\n",
      "  (97, 2357)\t0.04121770025030963\n",
      "  (97, 1236)\t0.05007834638626516\n",
      "  (97, 2419)\t0.034417441906621125\n",
      "  (97, 1413)\t0.051275078483692955\n",
      "  (97, 2375)\t0.03799792125072365\n",
      "  (97, 1257)\t0.05384354208822842\n",
      "  (97, 1776)\t0.051275078483692955\n",
      "  (97, 2341)\t0.0593626168184214\n",
      "  (97, 1594)\t0.028514240506675628\n",
      "  (97, 2340)\t0.12887536140608122\n",
      "  (97, 185)\t0.0759958425014473\n",
      "  (97, 1479)\t0.1141655962726034\n",
      "  (97, 1614)\t0.031022108254092517\n",
      "  (97, 2133)\t0.057111436889707115\n",
      "  (97, 2562)\t0.05384354208822842\n",
      "  (97, 2567)\t0.06362137313640899\n",
      "  (97, 2566)\t0.06362137313640899\n",
      "  (97, 1585)\t0.05418337472447603\n",
      "  (97, 1187)\t0.06329822611242365\n",
      "  (97, 2342)\t0.0722444996326347\n",
      "  (97, 1786)\t0.0589389925222207\n",
      "  (97, 1151)\t0.14894176258977057\n",
      "Column number:  2297\n"
     ]
    }
   ],
   "source": [
    "row = 5\n",
    "col = tfidf.vocabulary_['syllabifying'] # how is the tfidf matrix structured?\n",
    "\n",
    "print('Abstract: \"%s\"' % data.loc[row, 'ID'])\n",
    "print('TF-IDF score: %f' % matrix[row, col])\n",
    "\n",
    "print(matrix)\n",
    "matrix.shape\n",
    "\n",
    "print(\"Column number: \", col)\n",
    "\n",
    "# So clearly, the data is there now . . . we just need to extract the right data in the matrix to do the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 2595)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ====== pt. 2: importing the word2vec model and working with the dictionary file from the tf-idf =======\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6     \n",
      "0            the -0.242396  0.136115  0.176884 -0.106608 -0.111945  0.008947  \\\n",
      "1             of -0.191138  0.168684  0.132903 -0.099730 -0.113432 -0.022978   \n",
      "2            and -0.216545  0.155390  0.071324 -0.070429 -0.159644 -0.038712   \n",
      "3             in -0.227537  0.125394  0.097702 -0.155055 -0.133572  0.052193   \n",
      "4             to -0.257741  0.174983  0.165620 -0.139889 -0.098801 -0.049469   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "275556  workover  0.394763 -0.138997 -0.243322 -0.157992 -0.094953  0.127140   \n",
      "275557  condotel -0.091486  0.510353  0.115290 -0.514122 -0.335069  0.128298   \n",
      "275558    kuntey -0.232415  0.054326  0.415971 -0.029960  0.161247  0.246369   \n",
      "275559     houga  0.211834 -0.092607 -0.048265  0.064677  0.064417 -0.145476   \n",
      "275560    gp-stn -0.207188  0.077137  0.205872 -0.182772  0.243247  0.688170   \n",
      "\n",
      "             7         8         9    ...       191       192       193   \n",
      "0       0.135947 -0.082421  0.085838  ...  0.148953  0.064447 -0.001178  \\\n",
      "1       0.174045 -0.097945  0.046131  ...  0.089066  0.083751 -0.024087   \n",
      "2       0.064945 -0.013719  0.036322  ...  0.112115  0.035288 -0.061588   \n",
      "3       0.143991 -0.084266  0.066472  ...  0.125955  0.089060 -0.217870   \n",
      "4       0.122077 -0.031022  0.049582  ...  0.215590 -0.073144 -0.058039   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "275556  0.164249  0.024907 -0.035865  ...  0.513726  0.096588 -0.140386   \n",
      "275557  0.045652 -0.089612 -0.234540  ...  0.305439 -0.319811  0.252723   \n",
      "275558  0.131067 -0.145976  0.226713  ...  0.021065 -0.280798 -0.324447   \n",
      "275559  0.251887 -0.283335  0.474550  ...  0.188981  0.178981 -0.070167   \n",
      "275560  0.201276 -0.065501 -0.015827  ...  0.035363 -0.065787  0.152879   \n",
      "\n",
      "             194       195       196       197       198       199       200  \n",
      "0      -0.016101 -0.088447  0.021496 -0.059557  0.005552 -0.032828 -0.071551  \n",
      "1      -0.012805 -0.125353  0.010637 -0.118226  0.060810  0.001252 -0.073941  \n",
      "2      -0.004658 -0.107913  0.038720 -0.011822  0.065564  0.042976 -0.112689  \n",
      "3      -0.011854 -0.141282  0.020798 -0.082806 -0.056006 -0.044313 -0.163796  \n",
      "4      -0.070486 -0.115184  0.083460  0.000925  0.015039 -0.131154 -0.144334  \n",
      "...          ...       ...       ...       ...       ...       ...       ...  \n",
      "275556  0.167050 -0.310451 -0.135193 -0.152563 -0.139502  0.006745 -0.240002  \n",
      "275557  0.238032 -0.227958  0.048799  0.309579  0.033845  0.223744 -0.342862  \n",
      "275558  0.076553 -0.021072 -0.260636  0.222612 -0.362702  0.357780  0.081833  \n",
      "275559 -0.129690 -0.090388 -0.148845  0.259977  0.027815  0.047239  0.126365  \n",
      "275560  0.038332 -0.137882  0.274136 -0.291676 -0.071298 -0.380950 -0.393761  \n",
      "\n",
      "[275561 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importing the word2vec model as dataframe:\n",
    "\n",
    "model = '/Users/christianstenbro/AU/Applied_Cognitive_Science/Rep_rep_project/prediction_models/data and code/mag_200d_psy_eco_word2vec'\n",
    "\n",
    "model = pd.read_csv(model, sep=' ', skiprows = 1, header=None)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              the\n",
      "1               of\n",
      "2              and\n",
      "3               in\n",
      "4               to\n",
      "            ...   \n",
      "275556    workover\n",
      "275557    condotel\n",
      "275558      kuntey\n",
      "275559       houga\n",
      "275560      gp-stn\n",
      "Name: 0, Length: 275561, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(model.iloc[:,0]) # this is the column of works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>previous</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>studies</td>\n",
       "      <td>2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1\n",
       "0  abstract    79\n",
       "1        in  1151\n",
       "2  previous  1786\n",
       "3   studies  2251\n",
       "4   english   795"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining dictionary as a data frame\n",
    "\n",
    "# First, use dict.items() to get a group of the key-value pairs in the dictionary:\n",
    "\n",
    "items = dict.items(tfidf.vocabulary_)\n",
    "\n",
    "# Then, having this group as an object, use list(obj) to convert it to a list:\n",
    "\n",
    "items = list(items)\n",
    "\n",
    "# Finally, using this list as data, call numpy.array(data) to convert it to an array. But actually I want it to be a core pd data frame:\n",
    "\n",
    "dict_df = pd.DataFrame(items)\n",
    "\n",
    "dict_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             keys  values\n",
      "0        abstract      79\n",
      "1              in    1151\n",
      "2        previous    1786\n",
      "3         studies    2251\n",
      "4         english     795\n",
      "...           ...     ...\n",
      "2590   phonologic    1703\n",
      "2591          yes    2584\n",
      "2592         _obe      67\n",
      "2593  constitutes     527\n",
      "2594   misleading    1453\n",
      "\n",
      "[2595 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Renaming columns:\n",
    "\n",
    "dict_df.columns = ['keys', 'values']\n",
    "\n",
    "print(dict_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      values         keys\n",
      "0         79     abstract\n",
      "1       1151           in\n",
      "2       1786     previous\n",
      "3       2251      studies\n",
      "4        795      english\n",
      "...      ...          ...\n",
      "2590    1703   phonologic\n",
      "2591    2584          yes\n",
      "2592      67         _obe\n",
      "2593     527  constitutes\n",
      "2594    1453   misleading\n",
      "\n",
      "[2595 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# . . . and flipping the order:\n",
    "\n",
    "column_titles = ['values', 'keys']\n",
    "dict_df = dict_df.reindex(columns = column_titles)\n",
    "print(dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keys</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>previous</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>studies</td>\n",
       "      <td>2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>phonologic</td>\n",
       "      <td>1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>yes</td>\n",
       "      <td>2584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>_obe</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>constitutes</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>misleading</td>\n",
       "      <td>1453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2595 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             keys  values\n",
       "0        abstract      79\n",
       "1              in    1151\n",
       "2        previous    1786\n",
       "3         studies    2251\n",
       "4         english     795\n",
       "...           ...     ...\n",
       "2590   phonologic    1703\n",
       "2591          yes    2584\n",
       "2592         _obe      67\n",
       "2593  constitutes     527\n",
       "2594   misleading    1453\n",
       "\n",
       "[2595 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can index from the dataframe:\n",
    "\n",
    "dict_df['keys'] # either extracting the entire column\n",
    "dict_df['keys'][4] # or a single entry in a column\n",
    "dict_df[['keys', 'values']] # how would I extract and entire row with data from both columns though?\n",
    "\n",
    "# Link to indexing tips in Python: https://www.dataquest.io/blog/tutorial-indexing-dataframes-in-pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['values', 'keys'], dtype='object')\n",
      "RangeIndex(start=0, stop=2595, step=1)\n"
     ]
    }
   ],
   "source": [
    "# Examining some attribrutes of the data:\n",
    "\n",
    "print(dict_df.columns)\n",
    "print(dict_df.index) # this is useful knowledge when wanting to construct the for loop\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task is to remove the words from the word2vec model (model) that do not appear in the dictionary (dict_df) and create a new model data-frame.\n",
    "\n",
    "- One way to do this is by making a for-loop which goes through each row of our model dataframe, checking if there is a match with any of the words in the dictionaries. \n",
    "\n",
    "- If there is a match, the **word and its associated vector of dimensional values** should be added to a new two-column data-frame. \n",
    "\n",
    "- Ultimately, this data-frame will be as long as the dictionary, which should mean that it will be commensurable with the tf-idf matrix (elaborate).\n",
    "\n",
    "> Make a plan for how to concretely design the for loop. Remember that we need to loop through the word2vec model for each word entry (row) in our dict_df!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              the\n",
       "1               of\n",
       "2              and\n",
       "3               in\n",
       "4               to\n",
       "            ...   \n",
       "275556    workover\n",
       "275557    condotel\n",
       "275558      kuntey\n",
       "275559       houga\n",
       "275560      gp-stn\n",
       "Name: 0, Length: 275561, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df.shape\n",
    "model.shape\n",
    "\n",
    "model.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Matches:\n",
      "                   Term  Value\n",
      "0          syllabifying   2297\n",
      "1              grosjean   1037\n",
      "2       whethersubjects   2549\n",
      "3              thiscase   2360\n",
      "4             wordswere   2568\n",
      "..                  ...    ...\n",
      "80                 _eap     63\n",
      "81  feedbackconsistency    923\n",
      "82                  _ip     65\n",
      "83                  _ob     66\n",
      "84                 _obe     67\n",
      "\n",
      "[85 rows x 2 columns]\n",
      "Matched Data Frame:\n",
      "              0         1         2         3         4         5         6     \n",
      "0        abstract -0.164419  0.233158  0.253387 -0.060318  0.008594 -0.342084  \\\n",
      "1              in -0.227537  0.125394  0.097702 -0.155055 -0.133572  0.052193   \n",
      "2        previous -0.346380  0.006304  0.305970 -0.139675 -0.182512  0.049250   \n",
      "3         studies -0.249250  0.010476  0.088974 -0.260289 -0.054414 -0.030271   \n",
      "4         english -0.157916  0.097971  0.137283 -0.171298  0.103821  0.091728   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "2589        globe -0.021529 -0.040331  0.093697  0.071710  0.295056 -0.512503   \n",
      "2590   phonologic  0.166119  0.011583  0.617321  0.059052 -0.167412  0.449738   \n",
      "2591          yes -0.035224 -0.060090  0.592755 -0.317422 -0.246039  0.318855   \n",
      "2593  constitutes -0.191645  0.074492  0.268575 -0.336695 -0.071241 -0.189615   \n",
      "2594   misleading -0.356981 -0.131151  0.376909 -0.188344 -0.202470  0.300605   \n",
      "\n",
      "           7         8         9    ...       191       192       193   \n",
      "0     0.072384 -0.158849 -0.076478  ...  0.127368  0.031234 -0.286870  \\\n",
      "1     0.143991 -0.084266  0.066472  ...  0.125955  0.089060 -0.217870   \n",
      "2     0.182775 -0.317705  0.238295  ...  0.125932 -0.114897 -0.025431   \n",
      "3     0.194103 -0.325225  0.160901  ...  0.087359 -0.130020 -0.146982   \n",
      "4     0.227996 -0.237087  0.038814  ...  0.054863  0.129875 -0.239072   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2589  0.023171  0.033605  0.056809  ...  0.131217  0.100842 -0.334557   \n",
      "2590  0.174121  0.070267  0.134964  ... -0.254067 -0.242696  0.105087   \n",
      "2591  0.028493  0.371991  0.457179  ... -0.386318  0.015517  0.234608   \n",
      "2593  0.052777 -0.034520 -0.013880  ...  0.228042  0.233316 -0.016832   \n",
      "2594  0.007481  0.193716  0.441165  ... -0.095932 -0.173330  0.062536   \n",
      "\n",
      "           194       195       196       197       198       199       200  \n",
      "0     0.123983  0.043852  0.073327 -0.301613  0.008358 -0.154836 -0.144531  \n",
      "1    -0.011854 -0.141282  0.020798 -0.082806 -0.056006 -0.044313 -0.163796  \n",
      "2     0.251213 -0.250936 -0.024032  0.100205  0.017044  0.066197  0.045374  \n",
      "3     0.124166 -0.426162 -0.074545  0.017245 -0.096232 -0.001212 -0.059817  \n",
      "4     0.025619  0.082328  0.073301  0.082712  0.122293  0.147350 -0.081697  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2589  0.247142  0.097800 -0.080029 -0.135338 -0.150630  0.090382 -0.302848  \n",
      "2590  0.125844 -0.480237 -0.319941 -0.040487 -0.627847 -0.033238 -0.188857  \n",
      "2591  0.019007 -0.049388 -0.146896  0.577466  0.029020  0.323428 -0.002132  \n",
      "2593  0.101470 -0.230295  0.158561 -0.253239 -0.000294  0.102868 -0.145611  \n",
      "2594  0.115911 -0.243182 -0.190490  0.375547  0.047946  0.121369 -0.308563  \n",
      "\n",
      "[2510 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "# Trying out a for loop to extract terms from the model: \n",
    "\n",
    "# data 1 = dict_df \n",
    "# data 2 = model\n",
    "\n",
    "# First we create an empty data frame to store the matched rows from the model\n",
    "matched_df = pd.DataFrame(columns = model.columns)\n",
    "\n",
    "# Then we create an empty dataframe to store the missing matches\n",
    "missing_matches = pd.DataFrame(columns=['Term', 'Value'])\n",
    "\n",
    "# We iterate through each term in the model:\n",
    "for i, term in enumerate(dict_df['keys']):\n",
    "    # Checking if the terms exists in the dictionary\n",
    "    if term in model.iloc[:,0].values:\n",
    "        # If there is a match, we extract the entire row from the model and add it to the matched_df\n",
    "        row = model.loc[model.iloc[:,0] == term] # is this extracting the row?\n",
    "        row.index = [i]\n",
    "        matched_df = pd.concat([matched_df, row]) # how does this line work?\n",
    "    else:\n",
    "        # If no match is found, add the term to missing_matches\n",
    "        missing_matches.loc[len(missing_matches)] = [term, dict_df.iloc[i, 0]]\n",
    "\n",
    "matched_df = matched_df.sort_index()    \n",
    "\n",
    "# Print missing matches\n",
    "print(\"Missing Matches:\")\n",
    "print(missing_matches)\n",
    "\n",
    "# Print the matched data frame\n",
    "print(\"Matched Data Frame:\")\n",
    "print(matched_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         79\n",
       "1       1151\n",
       "2       1786\n",
       "3       2251\n",
       "4        795\n",
       "        ... \n",
       "2590    1703\n",
       "2591    2584\n",
       "2592      67\n",
       "2593     527\n",
       "2594    1453\n",
       "Name: values, Length: 2595, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>-0.164419</td>\n",
       "      <td>0.233158</td>\n",
       "      <td>0.253387</td>\n",
       "      <td>-0.060318</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>-0.342084</td>\n",
       "      <td>0.072384</td>\n",
       "      <td>-0.158849</td>\n",
       "      <td>-0.076478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127368</td>\n",
       "      <td>0.031234</td>\n",
       "      <td>-0.286870</td>\n",
       "      <td>0.123983</td>\n",
       "      <td>0.043852</td>\n",
       "      <td>0.073327</td>\n",
       "      <td>-0.301613</td>\n",
       "      <td>0.008358</td>\n",
       "      <td>-0.154836</td>\n",
       "      <td>-0.144531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>-0.227537</td>\n",
       "      <td>0.125394</td>\n",
       "      <td>0.097702</td>\n",
       "      <td>-0.155055</td>\n",
       "      <td>-0.133572</td>\n",
       "      <td>0.052193</td>\n",
       "      <td>0.143991</td>\n",
       "      <td>-0.084266</td>\n",
       "      <td>0.066472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125955</td>\n",
       "      <td>0.089060</td>\n",
       "      <td>-0.217870</td>\n",
       "      <td>-0.011854</td>\n",
       "      <td>-0.141282</td>\n",
       "      <td>0.020798</td>\n",
       "      <td>-0.082806</td>\n",
       "      <td>-0.056006</td>\n",
       "      <td>-0.044313</td>\n",
       "      <td>-0.163796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>previous</td>\n",
       "      <td>-0.346380</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>-0.139675</td>\n",
       "      <td>-0.182512</td>\n",
       "      <td>0.049250</td>\n",
       "      <td>0.182775</td>\n",
       "      <td>-0.317705</td>\n",
       "      <td>0.238295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125932</td>\n",
       "      <td>-0.114897</td>\n",
       "      <td>-0.025431</td>\n",
       "      <td>0.251213</td>\n",
       "      <td>-0.250936</td>\n",
       "      <td>-0.024032</td>\n",
       "      <td>0.100205</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>0.066197</td>\n",
       "      <td>0.045374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>studies</td>\n",
       "      <td>-0.249250</td>\n",
       "      <td>0.010476</td>\n",
       "      <td>0.088974</td>\n",
       "      <td>-0.260289</td>\n",
       "      <td>-0.054414</td>\n",
       "      <td>-0.030271</td>\n",
       "      <td>0.194103</td>\n",
       "      <td>-0.325225</td>\n",
       "      <td>0.160901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087359</td>\n",
       "      <td>-0.130020</td>\n",
       "      <td>-0.146982</td>\n",
       "      <td>0.124166</td>\n",
       "      <td>-0.426162</td>\n",
       "      <td>-0.074545</td>\n",
       "      <td>0.017245</td>\n",
       "      <td>-0.096232</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>-0.059817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>-0.157916</td>\n",
       "      <td>0.097971</td>\n",
       "      <td>0.137283</td>\n",
       "      <td>-0.171298</td>\n",
       "      <td>0.103821</td>\n",
       "      <td>0.091728</td>\n",
       "      <td>0.227996</td>\n",
       "      <td>-0.237087</td>\n",
       "      <td>0.038814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054863</td>\n",
       "      <td>0.129875</td>\n",
       "      <td>-0.239072</td>\n",
       "      <td>0.025619</td>\n",
       "      <td>0.082328</td>\n",
       "      <td>0.073301</td>\n",
       "      <td>0.082712</td>\n",
       "      <td>0.122293</td>\n",
       "      <td>0.147350</td>\n",
       "      <td>-0.081697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \n",
       "0  abstract -0.164419  0.233158  0.253387 -0.060318  0.008594 -0.342084  \\\n",
       "1        in -0.227537  0.125394  0.097702 -0.155055 -0.133572  0.052193   \n",
       "2  previous -0.346380  0.006304  0.305970 -0.139675 -0.182512  0.049250   \n",
       "3   studies -0.249250  0.010476  0.088974 -0.260289 -0.054414 -0.030271   \n",
       "4   english -0.157916  0.097971  0.137283 -0.171298  0.103821  0.091728   \n",
       "\n",
       "        7         8         9    ...       191       192       193       194   \n",
       "0  0.072384 -0.158849 -0.076478  ...  0.127368  0.031234 -0.286870  0.123983  \\\n",
       "1  0.143991 -0.084266  0.066472  ...  0.125955  0.089060 -0.217870 -0.011854   \n",
       "2  0.182775 -0.317705  0.238295  ...  0.125932 -0.114897 -0.025431  0.251213   \n",
       "3  0.194103 -0.325225  0.160901  ...  0.087359 -0.130020 -0.146982  0.124166   \n",
       "4  0.227996 -0.237087  0.038814  ...  0.054863  0.129875 -0.239072  0.025619   \n",
       "\n",
       "        195       196       197       198       199       200  \n",
       "0  0.043852  0.073327 -0.301613  0.008358 -0.154836 -0.144531  \n",
       "1 -0.141282  0.020798 -0.082806 -0.056006 -0.044313 -0.163796  \n",
       "2 -0.250936 -0.024032  0.100205  0.017044  0.066197  0.045374  \n",
       "3 -0.426162 -0.074545  0.017245 -0.096232 -0.001212 -0.059817  \n",
       "4  0.082328  0.073301  0.082712  0.122293  0.147350 -0.081697  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1151</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1786</td>\n",
       "      <td>previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2251</td>\n",
       "      <td>studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>795</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   values      keys\n",
       "0      79  abstract\n",
       "1    1151        in\n",
       "2    1786  previous\n",
       "3    2251   studies\n",
       "4     795   english"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ========== next step: remove missing words from TF_IDF matrix ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing matches list dimensions:  (85, 2)\n",
      "Dimensions of the new model data frame:  (2510, 201)\n",
      "Dimensions of the TF-IDF matrix:  (98, 2595)\n",
      "           0         1         2         3         4         5         6     \n",
      "0    -0.164419  0.233158  0.253387 -0.060318  0.008594 -0.342084  0.072384  \\\n",
      "1    -0.227537  0.125394  0.097702 -0.155055 -0.133572  0.052193  0.143991   \n",
      "2    -0.346380  0.006304  0.305970 -0.139675 -0.182512  0.049250  0.182775   \n",
      "3    -0.249250  0.010476  0.088974 -0.260289 -0.054414 -0.030271  0.194103   \n",
      "4    -0.157916  0.097971  0.137283 -0.171298  0.103821  0.091728  0.227996   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2505 -0.021529 -0.040331  0.093697  0.071710  0.295056 -0.512503  0.023171   \n",
      "2506  0.166119  0.011583  0.617321  0.059052 -0.167412  0.449738  0.174121   \n",
      "2507 -0.035224 -0.060090  0.592755 -0.317422 -0.246039  0.318855  0.028493   \n",
      "2508 -0.191645  0.074492  0.268575 -0.336695 -0.071241 -0.189615  0.052777   \n",
      "2509 -0.356981 -0.131151  0.376909 -0.188344 -0.202470  0.300605  0.007481   \n",
      "\n",
      "           7         8         9    ...       190       191       192   \n",
      "0    -0.158849 -0.076478 -0.046433  ...  0.127368  0.031234 -0.286870  \\\n",
      "1    -0.084266  0.066472  0.047409  ...  0.125955  0.089060 -0.217870   \n",
      "2    -0.317705  0.238295  0.004515  ...  0.125932 -0.114897 -0.025431   \n",
      "3    -0.325225  0.160901  0.054957  ...  0.087359 -0.130020 -0.146982   \n",
      "4    -0.237087  0.038814 -0.321406  ...  0.054863  0.129875 -0.239072   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2505  0.033605  0.056809  0.362343  ...  0.131217  0.100842 -0.334557   \n",
      "2506  0.070267  0.134964  0.014066  ... -0.254067 -0.242696  0.105087   \n",
      "2507  0.371991  0.457179  0.204451  ... -0.386318  0.015517  0.234608   \n",
      "2508 -0.034520 -0.013880  0.109261  ...  0.228042  0.233316 -0.016832   \n",
      "2509  0.193716  0.441165  0.099004  ... -0.095932 -0.173330  0.062536   \n",
      "\n",
      "           193       194       195       196       197       198       199  \n",
      "0     0.123983  0.043852  0.073327 -0.301613  0.008358 -0.154836 -0.144531  \n",
      "1    -0.011854 -0.141282  0.020798 -0.082806 -0.056006 -0.044313 -0.163796  \n",
      "2     0.251213 -0.250936 -0.024032  0.100205  0.017044  0.066197  0.045374  \n",
      "3     0.124166 -0.426162 -0.074545  0.017245 -0.096232 -0.001212 -0.059817  \n",
      "4     0.025619  0.082328  0.073301  0.082712  0.122293  0.147350 -0.081697  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2505  0.247142  0.097800 -0.080029 -0.135338 -0.150630  0.090382 -0.302848  \n",
      "2506  0.125844 -0.480237 -0.319941 -0.040487 -0.627847 -0.033238 -0.188857  \n",
      "2507  0.019007 -0.049388 -0.146896  0.577466  0.029020  0.323428 -0.002132  \n",
      "2508  0.101470 -0.230295  0.158561 -0.253239 -0.000294  0.102868 -0.145611  \n",
      "2509  0.115911 -0.243182 -0.190490  0.375547  0.047946  0.121369 -0.308563  \n",
      "\n",
      "[2510 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "# Checking some dimensions of the objects of interest:\n",
    "\n",
    "print(\"Missing matches list dimensions: \", missing_matches.shape)\n",
    "print(\"Dimensions of the new model data frame: \", matched_df.shape)\n",
    "print(\"Dimensions of the TF-IDF matrix: \", matrix.shape)\n",
    "\n",
    "df = matched_df.iloc[:, 1:]\n",
    "df = df.reset_index(drop = True)\n",
    "df.columns = range(200)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Term  Value\n",
      "0          syllabifying   2297\n",
      "1              grosjean   1037\n",
      "2       whethersubjects   2549\n",
      "3              thiscase   2360\n",
      "4             wordswere   2568\n",
      "..                  ...    ...\n",
      "80                 _eap     63\n",
      "81  feedbackconsistency    923\n",
      "82                  _ip     65\n",
      "83                  _ob     66\n",
      "84                 _obe     67\n",
      "\n",
      "[85 rows x 2 columns]\n",
      "values            2297\n",
      "keys      syllabifying\n",
      "Name: 164, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(missing_matches)\n",
    "# print(missing_matches['Index'])\n",
    "\n",
    "print(dict_df.iloc[164, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the matching_df as csv and sending to emil\n",
    "\n",
    "from pathlib import Path  \n",
    "filepath = Path('/Users/christianstenbro/Programming/ripley_project/Data_files/matching_df.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "matched_df.to_csv(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflection pad:\n",
    "\n",
    "- We want to modify the for loop creating the matched_df to also output the index for the missing matches\n",
    "\n",
    "- Then, we can use this information to remove the corresponding columns from the TF-IDF\n",
    "\n",
    "**FINALLY** we are ready to somehow (?) multiply the two matrices. \n",
    "\n",
    "- We want the output to have one number for each abstract - that's all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2297\n",
       "1     1037\n",
       "2     2549\n",
       "3     2360\n",
       "4     2568\n",
       "      ... \n",
       "80      63\n",
       "81     923\n",
       "82      65\n",
       "83      66\n",
       "84      67\n",
       "Name: Value, Length: 85, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_matches['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2297, 1037, 2549, 2360, 2568, 411, 2373, 1762, 1079, 1858, 1666, 34, 53, 62, 1702, 929, 2296, 1963, 1266, 2478, 1264, 2515, 1495, 800, 1484, 1452, 1341, 2202, 235, 237, 973, 2586, 2495, 2383, 658, 904, 1087, 1625, 2491, 1588, 758, 757, 2492, 756, 161, 322, 1101, 1102, 1508, 2263, 2452, 2059, 1867, 2198, 1078, 1294, 880, 2498, 1323, 1545, 1597, 2343, 346, 2077, 2197, 1027, 344, 604, 726, 2196, 1671, 2387, 1342, 2235, 2236, 1100, 1099, 1643, 1586, 64, 63, 923, 65, 66, 67]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of            1         2         3         4         5         6         7     \n",
       "0    -0.164419  0.233158  0.253387 -0.060318  0.008594 -0.342084  0.072384  \\\n",
       "1    -0.227537  0.125394  0.097702 -0.155055 -0.133572  0.052193  0.143991   \n",
       "2    -0.346380  0.006304  0.305970 -0.139675 -0.182512  0.049250  0.182775   \n",
       "3    -0.249250  0.010476  0.088974 -0.260289 -0.054414 -0.030271  0.194103   \n",
       "4    -0.157916  0.097971  0.137283 -0.171298  0.103821  0.091728  0.227996   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2589 -0.021529 -0.040331  0.093697  0.071710  0.295056 -0.512503  0.023171   \n",
       "2590  0.166119  0.011583  0.617321  0.059052 -0.167412  0.449738  0.174121   \n",
       "2591 -0.035224 -0.060090  0.592755 -0.317422 -0.246039  0.318855  0.028493   \n",
       "2593 -0.191645  0.074492  0.268575 -0.336695 -0.071241 -0.189615  0.052777   \n",
       "2594 -0.356981 -0.131151  0.376909 -0.188344 -0.202470  0.300605  0.007481   \n",
       "\n",
       "           8         9         10   ...       191       192       193   \n",
       "0    -0.158849 -0.076478 -0.046433  ...  0.127368  0.031234 -0.286870  \\\n",
       "1    -0.084266  0.066472  0.047409  ...  0.125955  0.089060 -0.217870   \n",
       "2    -0.317705  0.238295  0.004515  ...  0.125932 -0.114897 -0.025431   \n",
       "3    -0.325225  0.160901  0.054957  ...  0.087359 -0.130020 -0.146982   \n",
       "4    -0.237087  0.038814 -0.321406  ...  0.054863  0.129875 -0.239072   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2589  0.033605  0.056809  0.362343  ...  0.131217  0.100842 -0.334557   \n",
       "2590  0.070267  0.134964  0.014066  ... -0.254067 -0.242696  0.105087   \n",
       "2591  0.371991  0.457179  0.204451  ... -0.386318  0.015517  0.234608   \n",
       "2593 -0.034520 -0.013880  0.109261  ...  0.228042  0.233316 -0.016832   \n",
       "2594  0.193716  0.441165  0.099004  ... -0.095932 -0.173330  0.062536   \n",
       "\n",
       "           194       195       196       197       198       199       200  \n",
       "0     0.123983  0.043852  0.073327 -0.301613  0.008358 -0.154836 -0.144531  \n",
       "1    -0.011854 -0.141282  0.020798 -0.082806 -0.056006 -0.044313 -0.163796  \n",
       "2     0.251213 -0.250936 -0.024032  0.100205  0.017044  0.066197  0.045374  \n",
       "3     0.124166 -0.426162 -0.074545  0.017245 -0.096232 -0.001212 -0.059817  \n",
       "4     0.025619  0.082328  0.073301  0.082712  0.122293  0.147350 -0.081697  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2589  0.247142  0.097800 -0.080029 -0.135338 -0.150630  0.090382 -0.302848  \n",
       "2590  0.125844 -0.480237 -0.319941 -0.040487 -0.627847 -0.033238 -0.188857  \n",
       "2591  0.019007 -0.049388 -0.146896  0.577466  0.029020  0.323428 -0.002132  \n",
       "2593  0.101470 -0.230295  0.158561 -0.253239 -0.000294  0.102868 -0.145611  \n",
       "2594  0.115911 -0.243182 -0.190490  0.375547  0.047946  0.121369 -0.308563  \n",
       "\n",
       "[2510 rows x 200 columns]>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the TF-IDF matrix to panda pd\n",
    "\n",
    "tf_idf_df = pd.DataFrame.sparse.from_spmatrix(matrix)\n",
    "\n",
    "#print(tf_idf_df.shape)\n",
    "\n",
    "# Removing the columns contained in the missing_matches['Value']\n",
    "\n",
    "# Converting missing_matches['Value']\n",
    "\n",
    "type(missing_matches['Value'])\n",
    "\n",
    "missing_matches_list = list(missing_matches['Value'])\n",
    "print(missing_matches_list)\n",
    "\n",
    "# Sort tf-idf matrix and remove the columns corresponding to the values contained in the missing_matches list:\n",
    "\n",
    "tf_idf_matched_df = tf_idf_df[tf_idf_df.columns[~tf_idf_df.columns.isin(missing_matches_list)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the new model data frame:  (2510, 201)\n",
      "Dimensions of the new TF-IDF matrix:  (98, 2510)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matched_df.shape\n",
    "\n",
    "#print(tf_idf_matched_df)\n",
    "\n",
    "# Checking some dimensions of the objects of interest:\n",
    "\n",
    "print(\"Dimensions of the new model data frame: \", matched_df.shape)\n",
    "print(\"Dimensions of the new TF-IDF matrix: \", tf_idf_matched_df.shape)\n",
    "\n",
    "type(matched_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the matrices allign\n",
    "\n",
    "# Removing word column from matched dict file\n",
    "\n",
    "matched_df_removed_col = matched_df.iloc[: , 1:]\n",
    "\n",
    "matched_df_removed_col.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-index the dataframes to start with 0:\n",
    "\n",
    "tf_idf_matched_df_reindex = tf_idf_matched_df.reset_index(drop = True)\n",
    "matched_df_reindex = matched_df_removed_col.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.164419</td>\n",
       "      <td>0.233158</td>\n",
       "      <td>0.253387</td>\n",
       "      <td>-0.060318</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>-0.342084</td>\n",
       "      <td>0.072384</td>\n",
       "      <td>-0.158849</td>\n",
       "      <td>-0.076478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045325</td>\n",
       "      <td>0.127368</td>\n",
       "      <td>0.031234</td>\n",
       "      <td>-0.286870</td>\n",
       "      <td>0.123983</td>\n",
       "      <td>0.043852</td>\n",
       "      <td>0.073327</td>\n",
       "      <td>-0.301613</td>\n",
       "      <td>0.008358</td>\n",
       "      <td>-0.154836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.227537</td>\n",
       "      <td>0.125394</td>\n",
       "      <td>0.097702</td>\n",
       "      <td>-0.155055</td>\n",
       "      <td>-0.133572</td>\n",
       "      <td>0.052193</td>\n",
       "      <td>0.143991</td>\n",
       "      <td>-0.084266</td>\n",
       "      <td>0.066472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>0.125955</td>\n",
       "      <td>0.089060</td>\n",
       "      <td>-0.217870</td>\n",
       "      <td>-0.011854</td>\n",
       "      <td>-0.141282</td>\n",
       "      <td>0.020798</td>\n",
       "      <td>-0.082806</td>\n",
       "      <td>-0.056006</td>\n",
       "      <td>-0.044313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.346380</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>-0.139675</td>\n",
       "      <td>-0.182512</td>\n",
       "      <td>0.049250</td>\n",
       "      <td>0.182775</td>\n",
       "      <td>-0.317705</td>\n",
       "      <td>0.238295</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189315</td>\n",
       "      <td>0.125932</td>\n",
       "      <td>-0.114897</td>\n",
       "      <td>-0.025431</td>\n",
       "      <td>0.251213</td>\n",
       "      <td>-0.250936</td>\n",
       "      <td>-0.024032</td>\n",
       "      <td>0.100205</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>0.066197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.249250</td>\n",
       "      <td>0.010476</td>\n",
       "      <td>0.088974</td>\n",
       "      <td>-0.260289</td>\n",
       "      <td>-0.054414</td>\n",
       "      <td>-0.030271</td>\n",
       "      <td>0.194103</td>\n",
       "      <td>-0.325225</td>\n",
       "      <td>0.160901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150480</td>\n",
       "      <td>0.087359</td>\n",
       "      <td>-0.130020</td>\n",
       "      <td>-0.146982</td>\n",
       "      <td>0.124166</td>\n",
       "      <td>-0.426162</td>\n",
       "      <td>-0.074545</td>\n",
       "      <td>0.017245</td>\n",
       "      <td>-0.096232</td>\n",
       "      <td>-0.001212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.157916</td>\n",
       "      <td>0.097971</td>\n",
       "      <td>0.137283</td>\n",
       "      <td>-0.171298</td>\n",
       "      <td>0.103821</td>\n",
       "      <td>0.091728</td>\n",
       "      <td>0.227996</td>\n",
       "      <td>-0.237087</td>\n",
       "      <td>0.038814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091245</td>\n",
       "      <td>0.054863</td>\n",
       "      <td>0.129875</td>\n",
       "      <td>-0.239072</td>\n",
       "      <td>0.025619</td>\n",
       "      <td>0.082328</td>\n",
       "      <td>0.073301</td>\n",
       "      <td>0.082712</td>\n",
       "      <td>0.122293</td>\n",
       "      <td>0.147350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.021529</td>\n",
       "      <td>-0.040331</td>\n",
       "      <td>0.093697</td>\n",
       "      <td>0.071710</td>\n",
       "      <td>0.295056</td>\n",
       "      <td>-0.512503</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>0.033605</td>\n",
       "      <td>0.056809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176993</td>\n",
       "      <td>0.131217</td>\n",
       "      <td>0.100842</td>\n",
       "      <td>-0.334557</td>\n",
       "      <td>0.247142</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>-0.080029</td>\n",
       "      <td>-0.135338</td>\n",
       "      <td>-0.150630</td>\n",
       "      <td>0.090382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166119</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.617321</td>\n",
       "      <td>0.059052</td>\n",
       "      <td>-0.167412</td>\n",
       "      <td>0.449738</td>\n",
       "      <td>0.174121</td>\n",
       "      <td>0.070267</td>\n",
       "      <td>0.134964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155802</td>\n",
       "      <td>-0.254067</td>\n",
       "      <td>-0.242696</td>\n",
       "      <td>0.105087</td>\n",
       "      <td>0.125844</td>\n",
       "      <td>-0.480237</td>\n",
       "      <td>-0.319941</td>\n",
       "      <td>-0.040487</td>\n",
       "      <td>-0.627847</td>\n",
       "      <td>-0.033238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.035224</td>\n",
       "      <td>-0.060090</td>\n",
       "      <td>0.592755</td>\n",
       "      <td>-0.317422</td>\n",
       "      <td>-0.246039</td>\n",
       "      <td>0.318855</td>\n",
       "      <td>0.028493</td>\n",
       "      <td>0.371991</td>\n",
       "      <td>0.457179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017718</td>\n",
       "      <td>-0.386318</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>0.234608</td>\n",
       "      <td>0.019007</td>\n",
       "      <td>-0.049388</td>\n",
       "      <td>-0.146896</td>\n",
       "      <td>0.577466</td>\n",
       "      <td>0.029020</td>\n",
       "      <td>0.323428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.191645</td>\n",
       "      <td>0.074492</td>\n",
       "      <td>0.268575</td>\n",
       "      <td>-0.336695</td>\n",
       "      <td>-0.071241</td>\n",
       "      <td>-0.189615</td>\n",
       "      <td>0.052777</td>\n",
       "      <td>-0.034520</td>\n",
       "      <td>-0.013880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016186</td>\n",
       "      <td>0.228042</td>\n",
       "      <td>0.233316</td>\n",
       "      <td>-0.016832</td>\n",
       "      <td>0.101470</td>\n",
       "      <td>-0.230295</td>\n",
       "      <td>0.158561</td>\n",
       "      <td>-0.253239</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>0.102868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.356981</td>\n",
       "      <td>-0.131151</td>\n",
       "      <td>0.376909</td>\n",
       "      <td>-0.188344</td>\n",
       "      <td>-0.202470</td>\n",
       "      <td>0.300605</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.193716</td>\n",
       "      <td>0.441165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.394287</td>\n",
       "      <td>-0.095932</td>\n",
       "      <td>-0.173330</td>\n",
       "      <td>0.062536</td>\n",
       "      <td>0.115911</td>\n",
       "      <td>-0.243182</td>\n",
       "      <td>-0.190490</td>\n",
       "      <td>0.375547</td>\n",
       "      <td>0.047946</td>\n",
       "      <td>0.121369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2510 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6     \n",
       "0     NaN -0.164419  0.233158  0.253387 -0.060318  0.008594 -0.342084  \\\n",
       "1     NaN -0.227537  0.125394  0.097702 -0.155055 -0.133572  0.052193   \n",
       "2     NaN -0.346380  0.006304  0.305970 -0.139675 -0.182512  0.049250   \n",
       "3     NaN -0.249250  0.010476  0.088974 -0.260289 -0.054414 -0.030271   \n",
       "4     NaN -0.157916  0.097971  0.137283 -0.171298  0.103821  0.091728   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "2589  NaN -0.021529 -0.040331  0.093697  0.071710  0.295056 -0.512503   \n",
       "2590  NaN  0.166119  0.011583  0.617321  0.059052 -0.167412  0.449738   \n",
       "2591  NaN -0.035224 -0.060090  0.592755 -0.317422 -0.246039  0.318855   \n",
       "2593  NaN -0.191645  0.074492  0.268575 -0.336695 -0.071241 -0.189615   \n",
       "2594  NaN -0.356981 -0.131151  0.376909 -0.188344 -0.202470  0.300605   \n",
       "\n",
       "           7         8         9    ...       190       191       192   \n",
       "0     0.072384 -0.158849 -0.076478  ... -0.045325  0.127368  0.031234  \\\n",
       "1     0.143991 -0.084266  0.066472  ...  0.006355  0.125955  0.089060   \n",
       "2     0.182775 -0.317705  0.238295  ... -0.189315  0.125932 -0.114897   \n",
       "3     0.194103 -0.325225  0.160901  ... -0.150480  0.087359 -0.130020   \n",
       "4     0.227996 -0.237087  0.038814  ...  0.091245  0.054863  0.129875   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2589  0.023171  0.033605  0.056809  ...  0.176993  0.131217  0.100842   \n",
       "2590  0.174121  0.070267  0.134964  ... -0.155802 -0.254067 -0.242696   \n",
       "2591  0.028493  0.371991  0.457179  ...  0.017718 -0.386318  0.015517   \n",
       "2593  0.052777 -0.034520 -0.013880  ... -0.016186  0.228042  0.233316   \n",
       "2594  0.007481  0.193716  0.441165  ... -0.394287 -0.095932 -0.173330   \n",
       "\n",
       "           193       194       195       196       197       198       199  \n",
       "0    -0.286870  0.123983  0.043852  0.073327 -0.301613  0.008358 -0.154836  \n",
       "1    -0.217870 -0.011854 -0.141282  0.020798 -0.082806 -0.056006 -0.044313  \n",
       "2    -0.025431  0.251213 -0.250936 -0.024032  0.100205  0.017044  0.066197  \n",
       "3    -0.146982  0.124166 -0.426162 -0.074545  0.017245 -0.096232 -0.001212  \n",
       "4    -0.239072  0.025619  0.082328  0.073301  0.082712  0.122293  0.147350  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2589 -0.334557  0.247142  0.097800 -0.080029 -0.135338 -0.150630  0.090382  \n",
       "2590  0.105087  0.125844 -0.480237 -0.319941 -0.040487 -0.627847 -0.033238  \n",
       "2591  0.234608  0.019007 -0.049388 -0.146896  0.577466  0.029020  0.323428  \n",
       "2593 -0.016832  0.101470 -0.230295  0.158561 -0.253239 -0.000294  0.102868  \n",
       "2594  0.062536  0.115911 -0.243182 -0.190490  0.375547  0.047946  0.121369  \n",
       "\n",
       "[2510 rows x 200 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "matched_df_removed_col.reindex(columns=range(len(matched_df_removed_col.columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of     0     1     2     3     4     5     6     7     8     9     ...      2584   \n",
      "0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000  \\\n",
      "1    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "2    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "3    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "4    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...       ...   \n",
      "93   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "94   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "95   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "96   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.000000   \n",
      "97   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...  0.085028   \n",
      "\n",
      "    2585  2587  2588  2589  2590  2591  2592  2593  2594  \n",
      "0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "..   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "93   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "94   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "95   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "96   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "97   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[98 rows x 2510 columns]>\n",
      "<bound method NDFrame.head of            1         2         3         4         5         6         7     \n",
      "0    -0.164419  0.233158  0.253387 -0.060318  0.008594 -0.342084  0.072384  \\\n",
      "1    -0.227537  0.125394  0.097702 -0.155055 -0.133572  0.052193  0.143991   \n",
      "2    -0.346380  0.006304  0.305970 -0.139675 -0.182512  0.049250  0.182775   \n",
      "3    -0.249250  0.010476  0.088974 -0.260289 -0.054414 -0.030271  0.194103   \n",
      "4    -0.157916  0.097971  0.137283 -0.171298  0.103821  0.091728  0.227996   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2589 -0.021529 -0.040331  0.093697  0.071710  0.295056 -0.512503  0.023171   \n",
      "2590  0.166119  0.011583  0.617321  0.059052 -0.167412  0.449738  0.174121   \n",
      "2591 -0.035224 -0.060090  0.592755 -0.317422 -0.246039  0.318855  0.028493   \n",
      "2593 -0.191645  0.074492  0.268575 -0.336695 -0.071241 -0.189615  0.052777   \n",
      "2594 -0.356981 -0.131151  0.376909 -0.188344 -0.202470  0.300605  0.007481   \n",
      "\n",
      "           8         9         10   ...       191       192       193   \n",
      "0    -0.158849 -0.076478 -0.046433  ...  0.127368  0.031234 -0.286870  \\\n",
      "1    -0.084266  0.066472  0.047409  ...  0.125955  0.089060 -0.217870   \n",
      "2    -0.317705  0.238295  0.004515  ...  0.125932 -0.114897 -0.025431   \n",
      "3    -0.325225  0.160901  0.054957  ...  0.087359 -0.130020 -0.146982   \n",
      "4    -0.237087  0.038814 -0.321406  ...  0.054863  0.129875 -0.239072   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2589  0.033605  0.056809  0.362343  ...  0.131217  0.100842 -0.334557   \n",
      "2590  0.070267  0.134964  0.014066  ... -0.254067 -0.242696  0.105087   \n",
      "2591  0.371991  0.457179  0.204451  ... -0.386318  0.015517  0.234608   \n",
      "2593 -0.034520 -0.013880  0.109261  ...  0.228042  0.233316 -0.016832   \n",
      "2594  0.193716  0.441165  0.099004  ... -0.095932 -0.173330  0.062536   \n",
      "\n",
      "           194       195       196       197       198       199       200  \n",
      "0     0.123983  0.043852  0.073327 -0.301613  0.008358 -0.154836 -0.144531  \n",
      "1    -0.011854 -0.141282  0.020798 -0.082806 -0.056006 -0.044313 -0.163796  \n",
      "2     0.251213 -0.250936 -0.024032  0.100205  0.017044  0.066197  0.045374  \n",
      "3     0.124166 -0.426162 -0.074545  0.017245 -0.096232 -0.001212 -0.059817  \n",
      "4     0.025619  0.082328  0.073301  0.082712  0.122293  0.147350 -0.081697  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2589  0.247142  0.097800 -0.080029 -0.135338 -0.150630  0.090382 -0.302848  \n",
      "2590  0.125844 -0.480237 -0.319941 -0.040487 -0.627847 -0.033238 -0.188857  \n",
      "2591  0.019007 -0.049388 -0.146896  0.577466  0.029020  0.323428 -0.002132  \n",
      "2593  0.101470 -0.230295  0.158561 -0.253239 -0.000294  0.102868 -0.145611  \n",
      "2594  0.115911 -0.243182 -0.190490  0.375547  0.047946  0.121369 -0.308563  \n",
      "\n",
      "[2510 rows x 200 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_matched_df_reindex.head)\n",
    "print(matched_df_removed_col.head)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem could occur because of different indices. How can we check this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matrices are not aligned",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[39m@tf_idf_matched_df\u001b[39;49m\n",
      "File \u001b[0;32m~/Programming/ripley_project/venv/lib/python3.10/site-packages/pandas/core/frame.py:1629\u001b[0m, in \u001b[0;36mDataFrame.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__matmul__\u001b[39m(\u001b[39mself\u001b[39m, other: AnyArrayLike \u001b[39m|\u001b[39m DataFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   1626\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m \u001b[39m    Matrix multiplication using binary `@` operator in Python>=3.5.\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1629\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdot(other)\n",
      "File \u001b[0;32m~/Programming/ripley_project/venv/lib/python3.10/site-packages/pandas/core/frame.py:1582\u001b[0m, in \u001b[0;36mDataFrame.dot\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1580\u001b[0m common \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39munion(other\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   1581\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(common) \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(common) \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(other\u001b[39m.\u001b[39mindex):\n\u001b[0;32m-> 1582\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmatrices are not aligned\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1584\u001b[0m left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex(columns\u001b[39m=\u001b[39mcommon, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1585\u001b[0m right \u001b[39m=\u001b[39m other\u001b[39m.\u001b[39mreindex(index\u001b[39m=\u001b[39mcommon, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: matrices are not aligned"
     ]
    }
   ],
   "source": [
    "df@tf_idf_matched_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
